{"cells":[{"cell_type":"code","source":["# @title AlphaFold Fusion Premium ‚Äî All-in-One (AF Fidelity ‚Üë, pLDDT/Identity, Monomer/Multimer, AFDB-first, Reliable 3D) - 2025-12-10\n","# Correction: removed key=... on st.components.v1.html (Streamlit 1.28 does not support it)\n","# and added an HTML \"stamp\" to force remount of 3D viewers.\n","\n","import os, sys, subprocess, time, shutil\n","from pathlib import Path\n","\n","print(\"üß¨ AlphaFold Premium ‚Äî AF fidelity ‚Üë (MSA/Multimer/Recycles) + pLDDT + Identity + AFDB-first + Reliable 3D\")\n","print(\"=\" * 80)\n","\n","# Kill previous UI\n","os.system(\"pkill -f streamlit 2>/dev/null || true\")\n","os.system(\"pkill -f cloudflared 2>/dev/null || true\")\n","time.sleep(1)\n","\n","# PIP env\n","os.environ[\"PIP_DEFAULT_TIMEOUT\"] = \"900\"\n","os.environ[\"PIP_PROGRESS_BAR\"] = \"off\"\n","os.environ[\"PIP_DISABLE_PIP_VERSION_CHECK\"] = \"1\"\n","\n","def pip_install(args, timeout=2400, quiet=True):\n","    cmd = [sys.executable, \"-m\", \"pip\", \"install\"]\n","    if quiet: cmd.append(\"-q\")\n","    cmd += [\"--no-cache-dir\"] + args\n","    print(\"    ‚Üí pip\", \" \".join(args))\n","    return subprocess.run(cmd, timeout=timeout).returncode == 0\n","\n","# Base tools\n","subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"], check=False)\n","\n","# ColabFold\n","print(\"  ‚Üí colabfold[alphafold]\")\n","ok_cf = pip_install([\"colabfold[alphafold] @ https://codeload.github.com/sokrypton/ColabFold/zip/refs/heads/main\"], timeout=2400, quiet=False)\n","if not ok_cf:\n","    ok_cf = pip_install([\"colabfold[alphafold]==1.5.5\"], quiet=False) or pip_install([\"colabfold[alphafold]==1.5.4\"], quiet=False)\n","if not ok_cf:\n","    raise RuntimeError(\"colabfold[alphafold] installation failed.\")\n","\n","# Sci + UI deps\n","pip_install([\"numpy==1.26.4\"], quiet=False)\n","pip_install([\"pandas>=2,<3\"], quiet=False)\n","pip_install([\"tensorflow==2.18.*\", \"protobuf>=4.25,<6\"], quiet=False)\n","for pkg in [\n","    \"streamlit==1.28.0\",\n","    \"plotly==5.17.0\",\n","    \"py3Dmol==2.1.0\",\n","    \"biopython>=1.83,<2\",\n","    \"Pillow==10.1.0\",\n","    \"psutil==5.9.8\",\n","    \"gemmi==0.6.6\"\n","]:\n","    pip_install([pkg])\n","\n","# JAX consistent\n","def install_jax_gpu():\n","    import subprocess, sys, re, shutil\n","    def _run(cmd): return subprocess.run(cmd, check=False, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n","    def _pip(args):\n","        print(\"    ‚Üí pip\", \" \".join(args))\n","        return _run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-q\"] + args)\n","    _run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"jax-cuda12-plugin\", \"jaxlib\", \"jax\"])\n","    _pip([\"jax>=0.5.0,<0.6\", \"jaxlib>=0.5.0,<0.6\"])\n","    has_gpu = shutil.which(\"nvidia-smi\") is not None\n","    if has_gpu:\n","        try:\n","            import jaxlib as _jl\n","            jl_ver = getattr(_jl, \"__version__\", None) or _run([sys.executable,\"-c\",\"import jaxlib;print(jaxlib.__version__)\"]).stdout.strip()\n","            print(f\"üîß detected jaxlib: {jl_ver}\")\n","            if jl_ver and re.match(r\"^\\d+\\.\\d+\\.\\d+$\", jl_ver):\n","                r = _pip([f\"jax-cuda12-plugin=={jl_ver}\"])\n","                if r.returncode != 0:\n","                    x,y,_ = jl_ver.split(\".\"); alt=f\"{x}.{y}.0\"\n","                    print(f\"‚ö†Ô∏è plugin {jl_ver} unavailable ‚Üí trying {alt}\")\n","                    _pip([f\"jax-cuda12-plugin=={alt}\"])\n","            else:\n","                _pip([\"jax-cuda12-plugin>=0.5.0,<0.6\"])\n","        except Exception as e:\n","            print(\"‚ö†Ô∏è CUDA12 plugin not finalized:\", e)\n","    else:\n","        _run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"jax-cuda12-plugin\"])\n","    try:\n","        import jax\n","        print(f\"‚úÖ JAX ready ‚Äî backend: {jax.default_backend()} | devices: {jax.devices()}\")\n","    except Exception as e:\n","        print(\"‚ö†Ô∏è JAX verification:\", e)\n","\n","install_jax_gpu()\n","\n","# Check core libs\n","try:\n","    import numpy as _np, pandas as _pd, tensorflow as _tf\n","    print(f\"‚úÖ Versions: numpy={_np.__version__} | pandas={_pd.__version__} | tensorflow={_tf.__version__}\")\n","except Exception as e:\n","    print(\"‚ö†Ô∏è NumPy/Pandas/TF import failed:\", e)\n","\n","print(\"‚úÖ Dependencies installed\")\n","print(\"=\" * 80)\n","\n","# ---------------------- Streamlit Application ----------------------\n","app_code = r'''\n","import os, sys, subprocess, time, re, json, shutil, urllib.request, tempfile, secrets, hashlib\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","import streamlit as st\n","import plotly.graph_objects as go\n","import plotly.express as px\n","import py3Dmol, psutil, gemmi\n","\n","from Bio.PDB import PDBIO\n","from Bio.PDB.MMCIFParser import MMCIFParser\n","\n","# ---------- Page config ----------\n","st.set_page_config(page_title=\"AlphaFold Fusion Premium\", page_icon=\"üß¨\", layout=\"wide\", initial_sidebar_state=\"expanded\")\n","\n","BASE = Path(\"/content\") if Path(\"/content\").exists() else Path.cwd()\n","RESULTS_DIR = BASE / \"alphafold_results\"\n","RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n","\n","def new_run_root():\n","    run_id = time.strftime(\"%Y%m%d-%H%M%S\") + \"-\" + secrets.token_hex(3)\n","    root = RESULTS_DIR / f\"run_{run_id}\"\n","    root.mkdir(parents=True, exist_ok=True)\n","    st.session_state[\"_run_root\"] = str(root)\n","    return root\n","\n","def current_run_root():\n","    p = st.session_state.get(\"_run_root\")\n","    return Path(p) if p else RESULTS_DIR\n","\n","# ---------- CSS ----------\n","st.markdown(\"\"\"\n","<style>\n",":root { --primary:#4361ee; --secondary:#3a0ca3; --accent:#7209b7; --success:#4cc9f0; --warning:#f72585; --light:#f8f9fa; --dark:#212529; }\n",".main-header { font-size:3rem; background:linear-gradient(135deg,#4361ee 0%,#3a0ca3 100%); -webkit-background-clip:text; -webkit-text-fill-color:transparent; text-align:center; margin-bottom:1rem; font-weight:800; }\n",".sub-header { font-size:1.6rem; color:#3a0ca3; margin:1rem 0 .6rem 0; border-bottom:3px solid #4cc9f0; }\n",".feature-card { padding:1rem; border-radius:1rem; background:#fff; box-shadow:0 10px 25px rgba(0,0,0,.08); margin:1rem 0; }\n",".info-card { background:linear-gradient(135deg,#f8f9fa 0%,#e9ecef 100%); padding:1rem; border-radius:1rem; border-left:5px solid #4361ee; margin:1rem 0; }\n",".stButton>button { background:linear-gradient(135deg,#4361ee 0%,#3a0ca3 100%); color:#fff; border:none; padding:.6rem 1.2rem; border-radius:50px; font-weight:600; width:100%; }\n",".viewer-container { border-radius:1rem; overflow:hidden; box-shadow:0 10px 25px rgba(0,0,0,.1); margin:1rem 0; }\n","</style>\n","\"\"\", unsafe_allow_html=True)\n","\n","st.markdown('<div class=\"main-header\">üß¨ AlphaFold Fusion Premium</div>', unsafe_allow_html=True)\n","st.markdown('<p style=\"text-align:center;color:#666;margin-bottom:1rem;\">AF Fidelity ‚Üë (MSA/Multimer/Recycles) + pLDDT/Identity + AFDB + Reliable 3D</p>', unsafe_allow_html=True)\n","\n","# ---------- Session ----------\n","ss=st.session_state\n","for k,v in {\"results\":{}, \"job_dirs\":{}, \"fasta_paths\":{}, \"fasta_text\":\"\", \"aln_import\":{},\n","            \"_uniprot_name_cache\":{}, \"_acc_to_uniprot_cache\":{}, \"_afdb_cache\":{}}.items():\n","    ss.setdefault(k,v)\n","\n","# ---------- Utils: sequences / complexity ----------\n","def clean_sequence_advanced(seq: str) -> str:\n","    seq = re.sub(r\"[^ACDEFGHIKLMNPQRSTVWY:]\", \"\", (seq or \"\").upper())\n","    seq = re.sub(r\":+\", \":\", seq)\n","    return seq.strip(\":\")\n","\n","def detect_complex(seq: str) -> bool:\n","    return \":\" in (seq or \"\")\n","\n","def seq_length_total(seq: str) -> int:\n","    s = clean_sequence_advanced(seq)\n","    return sum(len(part) for part in s.split(\":\") if part)\n","\n","# ---------- Viewers: key-like stamp + CDN + pLDDT helpers ----------\n","def viewer_key(prefix, path=None, style=None, scheme=None, mono=None, chain=None, first=None):\n","    p = Path(path).name if path else \"mem\"\n","    try:\n","        mtime = os.path.getmtime(path) if path and os.path.exists(path) else 0\n","    except Exception:\n","        mtime = 0\n","    payload = f\"{p}|{mtime}|{style}|{scheme}|{mono}|{chain}|{first}\"\n","    return f\"{prefix}::{hashlib.md5(payload.encode()).hexdigest()}\"\n","\n","def apply_viewer_stamp(html: str, stamp: str) -> str:\n","    try:\n","        return f\"<!-- {stamp} -->\\n{html}\"\n","    except Exception:\n","        return html\n","\n","def patch_py3dmol_html(doc: str) -> str:\n","    # Force 3Dmol CDN with fallback\n","    try:\n","        import re as _re\n","        s = doc or \"\"\n","        s = _re.sub(\n","            r'src=\"https?://[^\"]*3Dmol[^\"]*\\.js\"',\n","            'src=\"https://cdn.jsdelivr.net/npm/3dmol@2.0.4/build/3Dmol-min.js\" onerror=\"this.onerror=null;this.src=\\'https://unpkg.com/3dmol/build/3Dmol-min.js\\';\"',\n","            s, count=1\n","        )\n","        return s\n","    except Exception:\n","        return doc\n","\n","def enhance_py3dmol_html(doc: str) -> str:\n","    # Recolor pLDDT if no coloring provided (does not affect Spectrum/Chain)\n","    try:\n","        inj = \"\"\"\n","<script>\n","(function(){\n","  function hasColorTokens(html){ return /colorfunc|colorscheme/.test(html); }\n","  function plddtColor(atom){\n","    var v = atom.b; if(v==null) return '#bfbfbf';\n","    if(v < 50) return '#ff8c42';\n","    if(v < 70) return '#ffd35a';\n","    if(v < 90) return '#8fd3ff';\n","    return '#2166f3';\n","  }\n","  try {\n","    if (typeof window === 'undefined') return;\n","    var v = window.viewer;\n","    var html = document.currentScript && document.currentScript.previousElementSibling ? document.currentScript.previousElementSibling.outerHTML : '';\n","    if (hasColorTokens(html)) return;\n","    if (v && typeof v.setStyle==='function'){\n","      v.setStyle({}, {cartoon:{colorfunc:plddtColor}});\n","      v.render();\n","    } else if (window.$3Dmol && window.$3Dmol.viewers){\n","      for (var k in window.$3Dmol.viewers){\n","        var vv = window.$3Dmol.viewers[k];\n","        try{ vv.setStyle({}, {cartoon:{colorfunc:plddtColor}}); vv.render(); }catch(e){}\n","      }\n","    }\n","  } catch(e){}\n","})();\n","</script>\n","\"\"\"\n","        if inj not in (doc or \"\"):\n","            return (doc or \"\") + \"\\n\" + inj\n","        return doc\n","    except Exception:\n","        return doc\n","\n","def af_detect_fmt_from_text(txt: str, guess: str | None = None) -> str:\n","    h = (txt or \"\").lstrip()[:2000]\n","    has_cif = (\"_atom_site.\" in h) or h.startswith(\"data_\")\n","    has_pdb = h.startswith((\"ATOM\",\"HETATM\",\"MODEL\",\"HEADER\",\"REMARK\"))\n","    if has_cif and not has_pdb: return \"cif\"\n","    if has_pdb and not has_cif: return \"pdb\"\n","    return guess or \"pdb\"\n","\n","def af_plddt_per_residue_by_chain_from_text(txt: str, fmt: str | None = None, sel_chain: str | None = None):\n","    from collections import OrderedDict, defaultdict\n","    per_chain = {}\n","    fmt = af_detect_fmt_from_text(txt, fmt)\n","    if fmt == \"pdb\":\n","        ch_map = defaultdict(lambda: OrderedDict())\n","        for ln in (txt or \"\").splitlines():\n","            if not ln.startswith(\"ATOM\"): continue\n","            if len(ln) < 66: continue\n","            atom = ln[12:16]\n","            if atom.strip() != \"CA\": continue\n","            chain = ln[21:22].strip() or \"A\"\n","            if sel_chain and chain != sel_chain: continue\n","            resseq = ln[22:26].strip(); icode = ln[26:27]\n","            key = (resseq, icode)\n","            try:\n","                b = float(ln[60:66].strip())\n","                if 0.0 <= b <= 100.0:\n","                    if key not in ch_map[chain]: ch_map[chain][key] = b\n","            except Exception:\n","                continue\n","        for ch, od in ch_map.items():\n","            vals = list(od.values())\n","            if vals: per_chain[ch] = vals\n","        return per_chain\n","    try:\n","        import gemmi, tempfile, os\n","        with tempfile.NamedTemporaryFile(\"w\", suffix=\".cif\", delete=False) as f:\n","            f.write(txt or \"\"); path = f.name\n","        stct = gemmi.read_structure(path)\n","        if len(stct)>0:\n","            model = stct[0]\n","            for ch in model:\n","                if not ch.is_polymer(): continue\n","                ch_name = ch.name\n","                if sel_chain and ch_name != sel_chain: continue\n","                vals=[]\n","                for res in ch:\n","                    if not res.is_amino_acid(): continue\n","                    ca = res.find_atom(\"CA\",\"\")\n","                    if ca is None:\n","                        bs=[]\n","                        for a in res:\n","                            try:\n","                                b=float(a.b_iso)\n","                                if 0.0 <= b <= 100.0: bs.append(b)\n","                            except: pass\n","                        if bs: vals.append(sum(bs)/len(bs)); continue\n","                    try:\n","                        b=float(ca.b_iso)\n","                        if 0.0 <= b <= 100.0: vals.append(b)\n","                    except: pass\n","                if vals: per_chain[ch_name]=vals\n","        try: os.remove(path)\n","        except: pass\n","    except Exception: pass\n","    return per_chain\n","\n","def af_bins_counts(vals):\n","    b = {\"Very high (>90)\":0, \"High (70‚Äì90)\":0, \"Low (50‚Äì70)\":0, \"Very low (<50)\":0}\n","    for v in vals:\n","        try: f=float(v)\n","        except: continue\n","        if f < 50: b[\"Very low (<50)\"] += 1\n","        elif f < 70: b[\"Low (50‚Äì70)\"] += 1\n","        elif f < 90: b[\"High (70‚Äì90)\"] += 1\n","        else: b[\"Very high (>90)\"] += 1\n","    return b, len(vals)\n","\n","def af_plddt_legend_html():\n","    return \"\"\"\n","    <div style=\"border-radius:10px;overflow:hidden;border:1px solid #dce1ea;max-width:360px;\">\n","      <div style=\"background:#e9f0ff;padding:10px 12px;font-weight:700;color:#163dff;\">Model Confidence</div>\n","      <div style=\"padding:10px 12px;background:#fff;\">\n","        <div style=\"display:flex;align-items:center;margin:6px 0;\">\n","          <span style=\"display:inline-block;width:14px;height:14px;background:#2166f3;border-radius:2px;margin-right:8px;\"></span>\n","          Very high (pLDDT > 90)\n","        </div>\n","        <div style=\"display:flex;align-items:center;margin:6px 0;\">\n","          <span style=\"display:inline-block;width:14px;height:14px;background:#8fd3ff;border-radius:2px;margin-right:8px;\"></span>\n","          High (70 ‚â§ pLDDT < 90)\n","        </div>\n","        <div style=\"display:flex;align-items:center;margin:6px 0;\">\n","          <span style=\"display:inline-block;width:14px;height:14px;background:#ffd35a;border-radius:2px;margin-right:8px;\"></span>\n","          Low (50 ‚â§ pLDDT < 70)\n","        </div>\n","        <div style=\"display:flex;align-items:center;margin:6px 0;\">\n","          <span style=\"display:inline-block;width:14px;height:14px;background:#ff8c42;border-radius:2px;margin-right:8px;\"></span>\n","          Very low (pLDDT < 50)\n","        </div>\n","      </div>\n","    </div>\n","    \"\"\"\n","\n","def build_af_plddt_figs_from_text(txt, fmt=None, title=\"pLDDT\", sel_chain=None):\n","    per_chain = af_plddt_per_residue_by_chain_from_text(txt, fmt, sel_chain=sel_chain)\n","    vals = [float(v) for arr in per_chain.values() for v in arr if v is not None and 0.0 <= float(v) <= 100.0]\n","    fig_hist = px.histogram(x=vals, nbins=40, range_x=[0, 100], labels={\"x\":\"pLDDT\",\"y\":\"Residues\"}, title=f\"pLDDT distribution ‚Äî {title}\")\n","    fig_hist.update_layout(margin=dict(l=10, r=10, t=40, b=10), bargap=0.02)\n","    counts, total = af_bins_counts(vals)\n","    labels_order = [\"Very high (>90)\",\"High (70‚Äì90)\",\"Low (50‚Äì70)\",\"Very low (<50)\"]\n","    colors = {\"Very high (>90)\":\"#2166f3\",\"High (70‚Äì90)\":\"#8fd3ff\",\"Low (50‚Äì70)\":\"#ffd35a\",\"Very low (<50)\":\"#ff8c42\"}\n","    fig_pie = px.pie(values=[counts[k] for k in labels_order], names=labels_order, title=\"pLDDT distribution (AF)\")\n","    fig_pie.update_traces(textposition='inside', textinfo='percent+label', marker=dict(colors=[colors[k] for k in labels_order]))\n","    fig_pie.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n","    mean_v = float(np.mean(vals)) if vals else 0.0\n","    fig_gauge = go.Figure(go.Indicator(\n","        mode=\"gauge+number\", value=mean_v, number={\"suffix\":\" pLDDT\",\"valueformat\":\".2f\"},\n","        gauge={\"axis\":{\"range\":[0,100]}, \"bar\":{\"color\":\"#2166f3\"},\n","               \"steps\":[{\"range\":[0,50],\"color\":\"#ff8c42\"},{\"range\":[50,70],\"color\":\"#ffd35a\"},{\"range\":[70,90],\"color\":\"#8fd3ff\"},{\"range\":[90,100],\"color\":\"#2166f3\"}],\n","               \"threshold\":{\"line\":{\"color\":\"black\",\"width\":2},\"thickness\":0.75,\"value\":mean_v}},\n","        title={\"text\":\"Average pLDDT\"}, domain={\"x\":[0,1],\"y\":[0,1]}\n","    ))\n","    fig_gauge.update_layout(margin=dict(l=10, r=10, t=40, b=10))\n","    return fig_hist, fig_pie, fig_gauge\n","\n","def build_af_plddt_extras_from_text(txt, fmt=None, sel_chain=None, title=\"pLDDT\"):\n","    per_chain = af_plddt_per_residue_by_chain_from_text(txt, fmt, sel_chain=sel_chain)\n","    vals = [float(v) for arr in per_chain.values() for v in arr if v is not None and 0.0 <= float(v) <= 100.0]\n","    fig_ecdf = px.ecdf(vals, labels={\"value\":\"pLDDT\",\"ECDF\":\"Cumulative fraction\"}, title=f\"ECDF ‚Äî {title}\")\n","    fig_ecdf.update_layout(margin=dict(l=10,r=10,t=40,b=10))\n","    counts,_ = af_bins_counts(vals)\n","    labels_order = [\"Very low (<50)\",\"Low (50‚Äì70)\",\"High (70‚Äì90)\",\"Very high (>90)\"]\n","    colors = {\"Very high (>90)\":\"#2166f3\",\"High (70‚Äì90)\":\"#8fd3ff\",\"Low (50‚Äì70)\":\"#ffd35a\",\"Very low (<50)\":\"#ff8c42\"}\n","    fig_stack = go.Figure()\n","    total = sum(counts.values()) or 1\n","    for lab in labels_order:\n","        v = counts.get(lab,0)\n","        fig_stack.add_trace(go.Bar(x=[v], y=[\"pLDDT\"], orientation=\"h\", marker=dict(color=colors.get(lab,\"#ccc\")), name=lab,\n","                                   hovertemplate=f\"{lab}: {v} ({100.0*v/total:.1f}%)<extra></extra>\"))\n","    fig_stack.update_layout(barmode=\"stack\", title=f\"Stacked pLDDT ‚Äî {title}\", margin=dict(l=10,r=10,t=40,b=10), showlegend=True)\n","    return fig_ecdf, fig_stack\n","\n","def display_plddt_panels(txt, fmt, label, sel_chain, key_prefix):\n","    if not txt:\n","        st.info(\"AF pLDDT: source empty.\")\n","        return\n","    # checkbox remains stable without key here\n","    if st.checkbox(\"Show pLDDT legend\", value=True):\n","        st.markdown(af_plddt_legend_html(), unsafe_allow_html=True)\n","    figH, figP, figG = build_af_plddt_figs_from_text(txt, fmt, title=str(Path(label).name if label else \"current\"), sel_chain=sel_chain)\n","    c1, c2 = st.columns([2,1])\n","    with c1: st.plotly_chart(figH, use_container_width=True)\n","    with c2:\n","        st.plotly_chart(figP, use_container_width=True)\n","        st.plotly_chart(figG, use_container_width=True)\n","    figE, figS = build_af_plddt_extras_from_text(txt, fmt, sel_chain=sel_chain, title=str(Path(label).name if label else \"current\"))\n","    c3, c4 = st.columns(2)\n","    with c3: st.plotly_chart(figE, use_container_width=True)\n","    with c4: st.plotly_chart(figS, use_container_width=True)\n","\n","# ---------- AFDB helpers + Smart fetch ----------\n","def _is_uniprot_acc(x: str) -> bool:\n","    return bool(re.fullmatch(r\"[A-Z0-9]{6,10}\", (x or \"\").strip()))\n","\n","def afdb_fetch_by_accession(acc: str):\n","    try:\n","        url = f\"https://alphafold.ebi.ac.uk/api/prediction/{acc}\"\n","        with urllib.request.urlopen(url, timeout=25) as r:\n","            data = json.loads(r.read().decode(\"utf-8\"))\n","        if isinstance(data, list) and data:\n","            best = sorted(data, key=lambda d: d.get(\"latestVersion\", 0), reverse=True)[0]\n","            return {\"pdb_url\": best.get(\"pdbUrl\"), \"cif_url\": best.get(\"cifUrl\"), \"bcif_url\": best.get(\"bcifUrl\"), \"acc\": acc}\n","    except Exception:\n","        pass\n","    return None\n","\n","def afdb_fetch_by_sequence(seq: str):\n","    try:\n","        if \":\" in seq: return None\n","        q = f\"https://alphafold.ebi.ac.uk/api/sequence/summary?id={seq}&type=sequence\"\n","        with urllib.request.urlopen(q, timeout=25) as r:\n","            data = json.loads(r.read().decode(\"utf-8\"))\n","        stcs = data.get(\"structures\") or []\n","        if stcs:\n","            s0 = stcs[0] or {}; summ = s0.get(\"summary\") or {}; url = summ.get(\"model_url\")\n","            out = {\"pdb_url\": None, \"cif_url\": None, \"bcif_url\": None, \"acc\": None}\n","            if isinstance(url, str):\n","                if url.lower().endswith(\".pdb\"): out[\"pdb_url\"]=url\n","                elif url.lower().endswith(\".cif\"): out[\"cif_url\"]=url\n","                elif url.lower().endswith(\".bcif\"): out[\"bcif_url\"]=url\n","            return out\n","    except Exception:\n","        pass\n","    return None\n","\n","def smart_afdb_fetch(name: str, seq: str):\n","    key = f\"{name}::{hashlib.sha1((seq or '').encode()).hexdigest()[:10]}\"\n","    if key in ss[\"_afdb_cache\"]:\n","        return ss[\"_afdb_cache\"][key]\n","    # 1) direct accession\n","    if _is_uniprot_acc(name):\n","        hit = afdb_fetch_by_accession(name)\n","        ss[\"_afdb_cache\"][key]=hit; return hit\n","    # 2) pattern in header\n","    m = re.search(r\"([A-Z0-9]{6,10})\", name or \"\")\n","    if m:\n","        hit = afdb_fetch_by_accession(m.group(1))\n","        if hit:\n","            ss[\"_afdb_cache\"][key]=hit; return hit\n","    # 3) last resort: summary by sequence (can be slow)\n","    hit = afdb_fetch_by_sequence(seq)\n","    ss[\"_afdb_cache\"][key]=hit\n","    return hit\n","\n","def resolve_uniref_to_uniprot(uniref_id: str):\n","    try:\n","        if not re.match(r\"^UniRef(100|90|50)_[A-Za-z0-9]+$\", uniref_id or \"\"):\n","            return None\n","        url_json = f\"https://rest.uniprot.org/uniref/{uniref_id}?format=json\"\n","        with urllib.request.urlopen(url_json, timeout=15) as r:\n","            j = json.loads(r.read().decode(\"utf-8\"))\n","        rep = (j.get(\"representativeMember\") or {})\n","        cand = rep.get(\"uniProtKBId\") or rep.get(\"accession\") or rep.get(\"id\")\n","        if isinstance(cand, str):\n","            m = re.search(r\"([A-Z0-9]{6,10})\", cand)\n","            if m: return m.group(1)\n","    except Exception:\n","        pass\n","    try:\n","        url_fa = f\"https://rest.uniprot.org/uniref/{uniref_id}.fasta\"\n","        with urllib.request.urlopen(url_fa, timeout=15) as r:\n","            head = r.read(4096).decode(\"utf-8\", \"ignore\")\n","        m = re.search(r\"RepID=([A-Z0-9]{6,10})\", head)\n","        if m: return m.group(1)\n","    except Exception:\n","        pass\n","    return None\n","\n","def resolve_accession_to_uniprot(acc: str, timeout=8):\n","    acc = (acc or \"\").strip()\n","    if not acc: return None\n","    if _is_uniprot_acc(acc): return acc\n","    if \"|\" in acc:\n","        toks = acc.split(\"|\")\n","        if len(toks) >= 2 and _is_uniprot_acc(toks[1]): return toks[1]\n","    if acc.startswith(\"UniRef\"):\n","        return resolve_uniref_to_uniprot(acc)\n","    return None\n","\n","def get_uniprot_name_from_uniprot(up: str, timeout=8):\n","    if not up: return None\n","    if up in ss[\"_uniprot_name_cache\"]:\n","        return ss[\"_uniprot_name_cache\"].get(up)\n","    # JSON record\n","    try:\n","        with urllib.request.urlopen(f\"https://rest.uniprot.org/uniprotkb/{up}.json\", timeout=timeout) as r:\n","            j = json.loads(r.read().decode(\"utf-8\", \"ignore\"))\n","        pdj = j.get(\"proteinDescription\") or {}\n","        rec = (pdj.get(\"recommendedName\") or {})\n","        full = ((rec.get(\"fullName\") or {}).get(\"value\")) if isinstance(rec, dict) else None\n","        if isinstance(full, str) and full.strip():\n","            ss[\"_uniprot_name_cache\"][up]=full.strip(); return full.strip()\n","        subs = pdj.get(\"submissionNames\") or []\n","        if isinstance(subs, list) and subs:\n","            full = ((subs[0] or {}).get(\"fullName\") or {}).get(\"value\")\n","            if isinstance(full, str) and full.strip():\n","                ss[\"_uniprot_name_cache\"][up]=full.strip(); return full.strip()\n","    except Exception:\n","        pass\n","    # TSV fallback\n","    try:\n","        with urllib.request.urlopen(f\"https://rest.uniprot.org/uniprotkb/search?query=accession:{up}&fields=accession,protein_name&format=tsv\", timeout=timeout) as r:\n","            txt = r.read().decode(\"utf-8\", \"ignore\")\n","        lines = [ln for ln in txt.splitlines() if ln.strip()]\n","        if len(lines) >= 2:\n","            header = lines[0].split(\"\\t\"); row = lines[1].split(\"\\t\")\n","            idx = header.index(\"Protein names\")\n","            raw = row[idx]\n","            name = re.split(r\"\\s+OS=\", raw)[0].strip()\n","            if name:\n","                ss[\"_uniprot_name_cache\"][up]=name; return name\n","    except Exception:\n","        pass\n","    ss[\"_uniprot_name_cache\"][up]=None\n","    return None\n","\n","def annotate_df_with_uniprot_info(df, acc_col=\"Accession\",\n","                                  col_up=\"Accession_UniProt\", col_name=\"UniProt_Name\",\n","                                  col_uniprot_url=\"UniProt_URL\", col_afdb_url=\"AFDB_URL\", timeout=8):\n","    try:\n","        if df is None or df.empty or acc_col not in df.columns: return df\n","        vals = df[acc_col].astype(str).tolist()\n","        uniq = sorted(set(v for v in vals if v))\n","        mp_up, mp_nm, mp_u, mp_a = {}, {}, {}, {}\n","        for a in uniq:\n","            if a in ss[\"_acc_to_uniprot_cache\"]:\n","                up = ss[\"_acc_to_uniprot_cache\"][a]\n","            else:\n","                up = resolve_accession_to_uniprot(a, timeout=timeout)\n","                ss[\"_acc_to_uniprot_cache\"][a] = up\n","            nm = get_uniprot_name_from_uniprot(up, timeout=timeout) if up else \"\"\n","            mp_up[a] = up or \"\"; mp_nm[a] = nm or \"\"\n","            mp_u[a]  = (f\"https://www.uniprot.org/uniprotkb/{up}\" if up else \"\")\n","            mp_a[a]  = (f\"https://alphafold.ebi.ac.uk/entry/{up}\" if up else \"\")\n","        s_up = df[acc_col].map(lambda x: mp_up.get(str(x), \"\"))\n","        s_nm = df[acc_col].map(lambda x: mp_nm.get(str(x), \"\"))\n","        s_u  = df[acc_col].map(lambda x: mp_u.get(str(x),  \"\"))\n","        s_a  = df[acc_col].map(lambda x: mp_a.get(str(x),  \"\"))\n","        def _ins(col, ser, after):\n","            if col in df.columns: df[col] = ser\n","            else:\n","                pos = list(df.columns).index(after)+1 if after in df.columns else len(df.columns)\n","                df.insert(pos, col, ser)\n","        _ins(col_up, s_up, acc_col)\n","        _ins(col_name, s_nm, col_up)\n","        _ins(col_uniprot_url, s_u, col_name)\n","        _ins(col_afdb_url, s_a, col_uniprot_url)\n","        return df\n","    except Exception:\n","        return df\n","\n","# ---------- PDB/CIF I/O (pLDDT robust) ----------\n","def cif_to_pdb_text_cif(cif_path: Path, pdb_out: Path) -> bool:\n","    try:\n","        parser=MMCIFParser(QUIET=True); stct=parser.get_structure(\"S\", str(cif_path))\n","        io=PDBIO(); io.set_structure(stct); io.save(str(pdb_out))\n","        return pdb_out.exists() and pdb_out.stat().st_size>0\n","    except Exception: return False\n","\n","def any_cif_to_pdb(cif_or_bcif_path: Path, pdb_out: Path) -> bool:\n","    try:\n","        stct=gemmi.read_structure(str(cif_or_bcif_path))\n","        txt=stct.make_minimal_pdb()\n","        open(pdb_out,\"w\").write(txt)\n","        return pdb_out.exists() and pdb_out.stat().st_size>0\n","    except Exception: return False\n","\n","def extract_plddt_from_pdb(p: Path):\n","    vals=[]\n","    try:\n","        with open(p,\"r\") as f:\n","            for ln in f:\n","                if not ln.startswith(\"ATOM\") or len(ln) < 66: continue\n","                try:\n","                    b = float(ln[60:66].strip())\n","                    if 0.0 <= b <= 100.0:\n","                        vals.append(b)\n","                except Exception:\n","                    continue\n","    except Exception as e:\n","        try: st.warning(f\"pLDDT read error {Path(p).name}: {e}\")\n","        except Exception: pass\n","    return vals\n","\n","def extract_plddt_from_cif(p: Path):\n","    vals=[]\n","    try:\n","        stct=gemmi.read_structure(str(p))\n","        for mod in stct:\n","            for ch in mod:\n","                for res in ch:\n","                    for a in res:\n","                        try:\n","                            b=float(a.b_iso)\n","                            if 0.0 <= b <= 100.0:\n","                                vals.append(b)\n","                        except Exception: pass\n","    except Exception:\n","        try:\n","            parser=MMCIFParser(QUIET=True); stct=parser.get_structure(\"S\", str(p))\n","            for a in stct.get_atoms():\n","                try:\n","                    b=float(a.get_bfactor())\n","                    if 0.0 <= b <= 100.0:\n","                        vals.append(b)\n","                except Exception: pass\n","        except Exception: pass\n","    return vals\n","\n","def list_polymer_chains(path: str):\n","    try:\n","        stct = gemmi.read_structure(str(path))\n","        chains=[]\n","        if len(stct)>0:\n","            for ch in stct[0]:\n","                if ch.is_polymer():\n","                    chains.append((ch.name, sum(1 for res in ch if res.is_amino_acid())))\n","        chains = sorted(chains, key=lambda x: x[1], reverse=True)\n","        return [c for c,_ in chains] if chains else []\n","    except Exception:\n","        return []\n","\n","# ---------- Monomer-only / Rendering ----------\n","def keep_first_model_pdb_text(txt: str) -> str:\n","    import re\n","    if re.search(r'^\\s*MODEL', txt, flags=re.M):\n","        m = re.search(r'^\\s*MODEL[^\\n]*\\n(.*?)(?:\\nENDMDL|\\Z)', txt, flags=re.S|re.M)\n","        if m:\n","            body = m.group(1)\n","            lines = [ln for ln in body.splitlines() if ln.startswith((\"ATOM\",\"HETATM\",\"ANISOU\",\"TER\"))]\n","            return \"\\n\".join(lines) + \"\\n\"\n","    return txt\n","\n","def keep_first_model_text(fmt: str, txt: str) -> str:\n","    if fmt == \"pdb\":\n","        return keep_first_model_pdb_text(txt)\n","    with tempfile.NamedTemporaryFile(\"w\", suffix=\".cif\", delete=False) as tmp:\n","        tmp.write(txt); tmp_path = tmp.name\n","    try:\n","        stct = gemmi.read_structure(tmp_path)\n","        s2 = gemmi.Structure()\n","        if len(stct)>0:\n","            s2.add_model(stct[0])\n","        s2.cell = stct.cell; s2.spacegroup = stct.spacegroup\n","        out = s2.make_minimal_pdb()\n","        return out\n","    except Exception:\n","        return txt\n","    finally:\n","        try: os.remove(tmp_path)\n","        except Exception: pass\n","\n","def render_py3d_html(txt: str, fmt: str, style: str, scheme: str, mono_only=False, sel_chain=None):\n","    viewer = py3Dmol.view(width=1000, height=650)\n","    viewer.addModel(txt, \"cif\" if fmt==\"cif\" else \"pdb\")\n","    viewer.setStyle({}, {})\n","    cs = {\"pLDDT (B-factor)\":\"bfactor\",\"Spectrum\":\"spectrum\",\"Chain\":\"chain\"}[scheme]\n","    def apply_style(sel):\n","        if style==\"Cartoon\": viewer.setStyle(sel, {\"cartoon\":{\"colorscheme\":cs}})\n","        elif style==\"Stick\": viewer.setStyle(sel, {\"stick\":{\"colorscheme\":cs,\"radius\":0.3}})\n","        elif style==\"Sphere\": viewer.setStyle(sel, {\"sphere\":{\"colorscheme\":cs,\"radius\":1.0}})\n","        elif style==\"Line\": viewer.setStyle(sel, {\"line\":{\"colorscheme\":cs}})\n","        elif style==\"Surface\": viewer.setStyle(sel, {\"surface\":{\"opacity\":0.85}})\n","    if mono_only and sel_chain:\n","        apply_style({\"chain\": sel_chain})\n","    else:\n","        apply_style({})\n","    viewer.setBackgroundColor(\"white\"); viewer.zoomTo()\n","    return viewer._make_html()\n","\n","# ---------- Ranking + models ----------\n","def parse_ranking(job_dir: Path):\n","    files=list(job_dir.rglob(\"ranking_debug.json\"))\n","    if not files: files = list(job_dir.rglob(\"ranking*.json\"))\n","    if not files: return {}\n","    try:\n","        d=json.load(open(files[0]))\n","        out={}\n","        if \"order\" in d and isinstance(d[\"order\"], list): out[\"order\"]=d[\"order\"]\n","        for k in (\"ranking_confidence\",\"plddts\",\"iptms\",\"ptms\"):\n","            if k in d and isinstance(d[k], dict): out[k]=d[k]\n","        return out\n","    except Exception:\n","        return {}\n","\n","def safe_avg_plddt_from_path(path: Path, fmt: str):\n","    vals = extract_plddt_from_pdb(path) if fmt==\"pdb\" else extract_plddt_from_cif(path)\n","    arr=[]\n","    for v in vals:\n","        try:\n","            vv = float(v)\n","            if vv < 0: vv = 0.0\n","            if vv > 100: vv = 100.0\n","            arr.append(vv)\n","        except Exception: pass\n","    return float(np.mean(arr)) if arr else None\n","\n","def harvest_models(job_dir: Path):\n","    rank=parse_ranking(job_dir)\n","    pdbs = sorted(job_dir.rglob(\"*.pdb\"), key=lambda x:x.stat().st_mtime)\n","    cifs = sorted(list(job_dir.rglob(\"*.cif\"))+list(job_dir.rglob(\"*.bcif\")), key=lambda x:x.stat().st_mtime)\n","    converted=[]\n","    if not pdbs and cifs:\n","        for c in cifs:\n","            out=c.with_suffix(\"\").with_name(c.stem + \"_converted.pdb\")\n","            try:\n","                if any_cif_to_pdb(c,out) or (c.suffix.lower()==\".cif\" and cif_to_pdb_text_cif(c,out)):\n","                    converted.append(out)\n","            except Exception: pass\n","        pdbs = sorted(converted, key=lambda x:x.stat().st_mtime)\n","\n","    def model_id_from_name(p: Path):\n","        name=p.name\n","        m=re.search(r\"(model_\\d+)\", name)\n","        if m: return m.group(1)\n","        m=re.search(r\"ranked_(\\d+)\", name)\n","        if m:\n","            try: return f\"model_{int(m.group(1))+1}\"\n","            except: pass\n","        m=re.search(r\"unrelaxed_rank_\\d+_model_(\\d+)\", name)\n","        if m: return f\"model_{m.group(1)}\"\n","        m=re.search(r\"model_(\\d+)_\", name)\n","        if m: return f\"model_{m.group(1)}\"\n","        return None\n","\n","    def guess_rank_from_name(name: str):\n","        m=re.search(r\"ranked_(\\d+)\", name)\n","        if m:\n","            try: return int(m.group(1))+1\n","            except: return None\n","        m=re.search(r\"rank_(\\d+)\", name)\n","        if m:\n","            try: return int(m.group(1))\n","            except: return None\n","        return None\n","\n","    all_entries=[(\"pdb\", p) for p in pdbs] + [(\"cif\", c) for c in cifs]\n","    order=rank.get(\"order\", []) if isinstance(rank, dict) else []\n","\n","    rows=[]\n","    for fmt, path in all_entries:\n","        mid = model_id_from_name(path)\n","        avg = safe_avg_plddt_from_path(path, fmt)\n","        rc  = (rank.get(\"ranking_confidence\", {}) or {}).get(mid) if mid else None\n","        ptm = (rank.get(\"ptms\", {}) or {}).get(mid) if mid else None\n","        iptm= (rank.get(\"iptms\", {}) or {}).get(mid) if mid else None\n","        if mid and order and mid in order:\n","            rpos = order.index(mid)+1\n","        else:\n","            rpos = guess_rank_from_name(path.name)\n","        rows.append({\n","            \"model_id\": mid or \"-\",\n","            \"file\": str(path),\n","            \"fmt\": fmt,\n","            \"avg_plddt\": avg,\n","            \"rank\": rpos,\n","            \"ranking_conf\": rc,\n","            \"ptm\": ptm,\n","            \"iptm\": iptm\n","        })\n","    rows = sorted(rows, key=lambda x: (x[\"rank\"] if x[\"rank\"] is not None else 9999, -(x[\"avg_plddt\"] or 0)))\n","    return rows, rank\n","\n","def analyze_results(job_dir: Path):\n","    rows, rank = harvest_models(job_dir)\n","    res={\"status\":\"error\",\"message\":\"No PDB/CIF\",\"models\":rows,\"ranking\":rank,\"coverage_png\":None}\n","    if rows: res[\"status\"]=\"success\"; res[\"message\"]=\"\"\n","    covs=list(job_dir.rglob(\"*coverage*.png\"))\n","    if covs: res[\"coverage_png\"]=str(sorted(covs, key=lambda x:x.stat().st_mtime)[-1])\n","    return res\n","\n","# ---------- Quality: post-prediction validation ----------\n","def validate_prediction(metrics: dict):\n","    warnings=[]\n","    if metrics is None: return warnings\n","    avg = metrics.get(\"avg_plddt\", 0) or 0\n","    if avg < 70:\n","        warnings.append(\"‚ö†Ô∏è Low pLDDT (<70) ‚Äî structure potentially unreliable.\")\n","    ptm = metrics.get(\"ptm\"); iptm = metrics.get(\"iptm\")\n","    if ptm is not None and ptm < 0.5:\n","        warnings.append(\"‚ö†Ô∏è PTM < 0.5 ‚Äî PPI interfaces possibly incorrect (multimers).\")\n","    if ptm is not None and iptm is not None and (iptm < 0.3 * ptm):\n","        warnings.append(\"‚ö†Ô∏è ipTM ‚â™ PTM ‚Äî dubious assembly (poor positioning).\")\n","    return warnings\n","\n","# ---------- ColabFold runners (fidelity + robustness) ----------\n","def estimate_msa_timeout(seq_length: int, mode: str) -> int:\n","    base = {\"mmseqs2_uniref_env\":1800, \"mmseqs2_uniref\":900, \"single_sequence\":300}.get(mode, 900)\n","    return int(base + (seq_length // 100) * 60)  # +1min / 100 aa\n","\n","def _run(cmd, timeout_sec, env):\n","    r=subprocess.run(cmd, check=False, capture_output=True, text=True, timeout=timeout_sec, env=env)\n","    return (r.returncode==0), ((r.stderr or \"\")+\"\\n\"+(r.stdout or \"\"))\n","\n","def run_with_jax_fallback(cmd, timeout_sec, base_env):\n","    strategies = [\n","        (\"GPU\", {\"JAX_PLATFORM_NAME\":\"gpu\"}),\n","        (\"GPU_no_plugin\", {\"JAX_PLUGINS\":\"disabled\",\"JAX_PLATFORM_NAME\":\"gpu\"}),\n","        (\"CPU\", {\"JAX_PLATFORM_NAME\":\"cpu\",\"JAX_PLUGINS\":\"disabled\"}),\n","    ]\n","    logs=[]\n","    for name, env_upd in strategies:\n","        env = base_env.copy(); env.update(env_upd)\n","        ok, log = _run(cmd, timeout_sec, env)\n","        logs.append(f\"[{name}] {'OK' if ok else 'FAIL'}\\n{log}\")\n","        if ok: return True, \"\\n\\n\".join(logs)\n","    return False, \"\\n\\n\".join(logs)\n","\n","def run_colabfold_advanced(fasta_file: str, output_dir: str, params: dict, seq_len: int):\n","    exe = shutil.which(\"colabfold_batch\")\n","    cmd_base = [exe or sys.executable, *([] if exe else [\"-m\",\"colabfold.batch\"]), fasta_file, output_dir]\n","\n","    # Mapping MSA\n","    strat = params.get(\"msa_strategy\",\"full\")  # full | fast | minimal\n","    msa_cli = {\"full\":\"mmseqs2_uniref_env\",\"fast\":\"mmseqs2_uniref\",\"minimal\":\"single_sequence\"}[strat]\n","\n","    pair_cli = params.get(\"pair_mode\",\"unpaired_paired\").replace(\"+\",\"_\")\n","    model_type = params.get(\"model_type\",\"auto\")\n","    use_templates = bool(params.get(\"use_templates\", True))\n","    use_amber = bool(params.get(\"use_amber\", False))\n","    num_models = int(params.get(\"num_models\", 1))\n","    num_recycles = int(params.get(\"num_recycles\", 3))\n","    stop_at_score = params.get(\"stop_at_score\")\n","\n","    has_gpu = shutil.which(\"nvidia-smi\") is not None\n","    base_env = os.environ.copy()\n","    base_env.setdefault(\"TF_CPP_MIN_LOG_LEVEL\",\"3\")\n","    base_env.setdefault(\"XLA_PYTHON_CLIENT_PREALLOCATE\",\"false\")\n","    base_env.setdefault(\"XLA_PYTHON_CLIENT_MEM_FRACTION\",\"0.75\")\n","    base_env.setdefault(\"TF_FORCE_GPU_ALLOW_GROWTH\",\"true\")\n","\n","    def build(msa, nmodels, nrecy, use_tmpl, use_amb, extra=None):\n","        c = cmd_base + [\n","            \"--model-type\", model_type, \"--msa-mode\", msa,\n","            \"--num-models\", str(nmodels), \"--num-recycle\", str(nrecy),\n","            \"--pair-mode\", pair_cli, \"--rank\",\"auto\",\"--random-seed\",\"42\",\n","            \"--disable-unified-memory\",\"--recompile-padding\",\"1\"\n","        ]\n","        if (not has_gpu) and (\"--max-msa\" not in (extra or [])):\n","            c += [\"--max-msa\",\"256:256\",\"--disable-cluster-profile\"]\n","        if use_amb: c.append(\"--amber\")\n","        if use_tmpl: c.append(\"--templates\")\n","        if stop_at_score: c += [\"--stop-at-score\", str(stop_at_score)]\n","        jp = params.get(\"jobname_prefix\")\n","        if jp: c += [\"--jobname-prefix\", str(jp), \"--overwrite-existing-results\"]\n","        if extra: c += extra\n","        return c\n","\n","    # 1) try \"full\"\n","    cmd1 = build(msa_cli, num_models, num_recycles, use_templates, use_amber)\n","    tmo1 = estimate_msa_timeout(seq_len, msa_cli)\n","    ok1, log1 = run_with_jax_fallback(cmd1, timeout_sec=tmo1, base_env=base_env)\n","    if ok1: return True, \"[full] OK\\n\" + log1\n","\n","    # 2) fallback \"fast\"\n","    if strat != \"minimal\":\n","        cmd2 = build(\"mmseqs2_uniref\", num_models, num_recycles, use_templates, use_amber, extra=[\"--max-msa\",\"256:256\"])\n","        tmo2 = estimate_msa_timeout(seq_len, \"mmseqs2_uniref\")\n","        ok2, log2 = run_with_jax_fallback(cmd2, timeout_sec=tmo2, base_env=base_env)\n","        if ok2: return True, \"[fast] OK\\n\" + log1 + \"\\n\" + log2\n","\n","    # 3) last resort \"minimal\"\n","    cmd3 = build(\"single_sequence\", max(1, min(2, num_models)), max(1, min(4, num_recycles)), False, False, extra=[\"--max-msa\",\"64:64\",\"--disable-cluster-profile\"])\n","    tmo3 = estimate_msa_timeout(seq_len, \"single_sequence\")\n","    ok3, log3 = run_with_jax_fallback(cmd3, timeout_sec=tmo3, base_env=base_env)\n","    if ok3: return True, \"[minimal] OK\\n\" + log1 + (\"\\n\" + (log2 if strat!=\"minimal\" else \"\")) + \"\\n\" + log3\n","\n","    return False, \"[full/fast/minimal] Failures\\n\" + log1 + (\"\\n\" + (log2 if strat!=\"minimal\" else \"\")) + \"\\n\" + log3\n","\n","# ===== Helpers Identity ‚Üí 3D (text) =====\n","def format_pair_alignment_html(q_line: str, t_line: str, wrap: int = 120, highlight_identity: bool = True):\n","    chunks=[]\n","    for i in range(0, max(len(q_line or \"\"), len(t_line or \"\")), wrap):\n","        qc=(q_line or \"\")[i:i+wrap]; tc=(t_line or \"\")[i:i+wrap]\n","        chunks.append(qc); chunks.append(tc); chunks.append(\"\")\n","    return \"<pre style='font-family:ui-monospace;white-space:pre-wrap;'>\" + \"\\n\".join(chunks) + \"</pre>\"\n","\n","def get_best_query_model(ss, seq_name: str):\n","    res = (ss.get(\"results\") or {}).get(seq_name)\n","    if not res or res.get(\"status\")!=\"success\": return None, None, None\n","    models = res.get(\"models\") or []\n","    if not models: return None, None, None\n","    best = sorted(models, key=lambda m: (m[\"rank\"] if m[\"rank\"] is not None else 9999, -(m[\"avg_plddt\"] or 0)))[0]\n","    path = best[\"file\"]; fmt = \"cif\" if str(path).lower().endswith((\".cif\",\".bcif\")) else \"pdb\"\n","    return path, fmt, best\n","\n","def parse_fasta_complete(text: str):\n","    seqs=[]; head=None; buf=[]\n","    for ln in (text or \"\").splitlines():\n","        ln=ln.strip()\n","        if not ln:\n","            if head and buf: seqs.append((head,\"\".join(buf))); head=None; buf=[]\n","            continue\n","        if ln.startswith(\">\"):\n","            if head and buf: seqs.append((head,\"\".join(buf)))\n","            head=ln[1:].strip(); buf=[]\n","        else:\n","            if head is None and not buf: head=ln\n","            else: buf.append(ln)\n","    if head and buf: seqs.append((head,\"\".join(buf)))\n","    return seqs\n","\n","def parse_custom_text_results(text: str):\n","    lines = [ln.rstrip() for ln in (text or \"\").splitlines() if ln.strip()!=\"\"]\n","    if not lines: return None\n","    i=0; query_id=None; query_seq_raw=[]\n","    while i < len(lines) and query_id is None:\n","        if lines[i].startswith(\">\"):\n","            query_id = lines[i][1:].strip().split()[0]\n","            i += 1\n","            while i < len(lines) and not lines[i].startswith(\">\"):\n","                query_seq_raw.append(re.sub(r\"\\s+\",\"\", lines[i])); i += 1\n","        else:\n","            i += 1\n","    if not query_id: return None\n","    query_seq = re.sub(r\"[^A-Za-z]\", \"\", \"\".join(query_seq_raw)).upper().replace(\"-\", \"\")\n","    hits=[]\n","    def _toi(x):\n","        try: return int(x)\n","        except: return None\n","    def _tof(x):\n","        try: return float(str(x).replace(\"E\",\"e\"))\n","        except: return None\n","    while i < len(lines):\n","        if not lines[i].startswith(\">\"):\n","            i += 1; continue\n","        hdr = lines[i][1:].strip(); toks = hdr.split()\n","        h_id = toks[0]\n","        score   = _tof(toks[1]) if len(toks)>1 else None\n","        idfrac  = _tof(toks[2]) if len(toks)>2 else None\n","        evalue  = _tof(toks[3]) if len(toks)>3 else None\n","        q_start = _toi(toks[4]) if len(toks)>4 else None\n","        q_end   = _toi(toks[5]) if len(toks)>5 else None\n","        q_len   = _toi(toks[6]) if len(toks)>6 else None\n","        t_start = _toi(toks[7]) if len(toks)>7 else None\n","        t_end   = _toi(toks[8]) if len(toks)>8 else None\n","        t_len   = _toi(toks[9]) if len(toks)>9 else None\n","        i += 1\n","        targ_buf=[]\n","        while i < len(lines) and not lines[i].startswith(\">\"):\n","            targ_buf.append(re.sub(r\"\\s+\",\"\", lines[i])); i += 1\n","        t_line = \"\".join(targ_buf)\n","        q_line=[]; iq=0\n","        for ch in t_line:\n","            if ch == \"-\":\n","                if iq < len(query_seq): q_line.append(query_seq[iq]); iq += 1\n","                else: q_line.append(\"-\")\n","            elif ch.islower():\n","                q_line.append(\"-\")\n","            else:\n","                if iq < len(query_seq): q_line.append(query_seq[iq]); iq += 1\n","                else: q_line.append(\"-\")\n","        q_line=\"\".join(q_line)\n","        a=0; n=0\n","        for q,t in zip(q_line,t_line):\n","            if q!=\"-\":\n","                if t!=\"-\":\n","                    n+=1; a += (q.upper()==t.upper())\n","        ident_pct = (100.0*a/n) if n>0 else None\n","        covered = sum(1 for q,t in zip(q_line,t_line) if q!=\"-\")\n","        cov_q = round(100.0 * covered / len(query_seq), 1) if len(query_seq) else None\n","        hits.append({\n","            \"acc\":h_id,\"score\":score,\"HeaderIdentity_%\":(idfrac*100.0 if (idfrac is not None and idfrac<=1.0) else idfrac),\"Evalue\":evalue,\n","            \"q_start\":q_start,\"q_end\":q_end,\"q_len\":q_len,\"t_start\":t_start,\"t_end\":t_end,\"t_len\":t_len,\n","            \"q_line\":q_line,\"t_line\":t_line,\n","            \"Identity_%\":ident_pct,\"Cov_query_%\":cov_q,\"Aligned_core\":n\n","        })\n","    return {\"source\":\"import-text\",\"name\":query_id,\"query_header\":query_id,\"query_seq\":query_seq,\"query_len\":len(query_seq),\"hits\":hits}\n","\n","# ---------- Sidebar ----------\n","with st.sidebar:\n","    page = st.radio(\"Sections\", [\"üè† Home\",\"üìä Predictions\",\"üìà Results\",\"üëÅÔ∏è 3D Visualization\",\"‚öôÔ∏è Settings\"], key=\"nav_page\")\n","    st.markdown(\"---\")\n","    ss.setdefault(\"view_mode\", \"pLDDT (structures)\")\n","    st.radio(\"Display criterion\", [\"pLDDT (structures)\", \"Identity (%) (alignments)\"],\n","             index=(0 if ss[\"view_mode\"].startswith(\"pLDDT\") else 1), key=\"view_mode\")\n","    st.caption(\"Identity Mode = your imported alignments; pLDDT = ColabFold/AFDB structures.\")\n","\n","# ===================== PAGES =====================\n","current_page = ss.get(\"nav_page\", \"üè† Home\")\n","\n","# ---------- UI: Home ----------\n","if current_page == \"üè† Home\":\n","    st.markdown('<div class=\"feature-card\"><b>üéØ About</b><br/>AlphaFold-faithful ColabFold predictions (rich MSA, paired multimer, adapted recycles) + pLDDT/Identity + AFDB + reliable 3D.</div>', unsafe_allow_html=True)\n","    st.markdown('<div class=\"info-card\"><b>üìã FASTA</b><pre>>Name\\nSEQUENCE\\n\\n>Complex_AB\\nSEQ_A:SEQ_B</pre></div>', unsafe_allow_html=True)\n","\n","# ---------- UI: Predictions ----------\n","elif current_page == \"üìä Predictions\":\n","    st.markdown('<div class=\"sub-header\">üî¨ Prediction Configuration</div>', unsafe_allow_html=True)\n","    fa = st.text_area(\"FASTA (1 block per protein/complex):\", key=\"fasta_text\", height=220, placeholder=\">Name\\nSEQUENCE\\n\\n>Complex\\nSEQ_A:SEQ_B\")\n","    valid,warns=([],[])\n","    if fa.strip():\n","        seqs=parse_fasta_complete(fa)\n","        tmp=[]; warns=[]\n","        for name, seq in seqs:\n","            s=clean_sequence_advanced(seq)\n","            if not s: warns.append(f\"‚ùå {name}: empty sequence after cleaning\"); continue\n","            tmp.append((name or 'sequence', s))\n","        valid=tmp\n","        if valid: st.success(f\"{len(valid)} valid sequence(s).\")\n","        for w in warns: st.warning(w)\n","\n","    tab1,tab2=st.tabs([\"üéØ Base\",\"üîß Advanced\"])\n","    with tab1:\n","        c1,c2,c3=st.columns(3)\n","        with c1:\n","            quality = st.selectbox(\"Quality profile\", [\"Classic\",\"Fast\",\"High precision\"], index=0, help=\"Adjusts recycles / MSA.\")\n","            msa_strategy = st.selectbox(\"MSA Strategy\", [\"Complete (UniRef+Environ.)\",\"Fast (UniRef)\",\"Minimal (single)\"], index=0)\n","        with c2:\n","            num_models=st.slider(\"Number of models\",1,5,5, help=\"5 recommended\")\n","            base_recycles=st.slider(\"Recycle cycles (min)\",1,20,6, help=\"6 monomer min ‚Ä¢ 12 multimer min\")\n","        with c3:\n","            use_templates=st.checkbox(\"Templates (PDB)\", True)\n","            use_amber=st.checkbox(\"Relax AMBER\", False)\n","    with tab2:\n","        c1,c2=st.columns(2)\n","        with c1:\n","            model_type_ui=st.selectbox(\"Model type (auto recommended)\",[\"auto\",\"alphafold2_multimer_v3\",\"alphafold2_ptm\"],0)\n","            pair_mode_ui=st.selectbox(\"MSA pairing\",[\"auto\",\"paired\",\"unpaired\",\"unpaired_paired\"],0)\n","        with c2:\n","            stop_at_score=st.number_input(\"Stop pLDDT (0 = off)\", 0.0, 100.0, 0.0, 1.0)\n","            purge_old = st.checkbox(\"üßπ Purge old results (optional)\", False)\n","    strict_mono = st.checkbox(\"üß™ Strict monomer mode (disables pair-mode)\", value=False)\n","    no_homologs = st.checkbox(\"üî¨ Protein without known homologs (disables templates)\", value=False, help=\"Use if no known similarity ‚Äî otherwise keep templates.\")\n","\n","    # Map UI ‚Üí internal\n","    msa_map = {\"Complete (UniRef+Environ.)\":\"full\",\"Fast (UniRef)\":\"fast\",\"Minimal (single)\":\"minimal\"}\n","    msa_strategy_key = msa_map.get(msa_strategy, \"full\")\n","\n","    if st.button(\"üöÄ Launch Predictions\", type=\"primary\", use_container_width=True):\n","        if not valid:\n","            st.error(\"No valid sequences.\")\n","        else:\n","            if purge_old:\n","                shutil.rmtree(RESULTS_DIR, ignore_errors=True)\n","                RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n","            # New isolated run + memory state purge\n","            run_root = new_run_root()\n","            ss.results = {}; ss.job_dirs = {}; ss.fasta_paths = {}\n","\n","            prog=st.progress(0); info=st.empty(); results={}\n","            for i,(name,seq) in enumerate(valid):\n","                safe=re.sub(r\"[^A-Za-z0-9_]\", \"_\", name or f\"seq{i+1}\")\n","                fa_path=str(Path(\"/tmp\")/f\"{safe}.fasta\"); open(fa_path,\"w\").write(f\">{safe}\\n{seq}\\n\")\n","\n","                is_complex = detect_complex(seq)\n","                seq_len = seq_length_total(seq)\n","\n","                # Recommended recycles\n","                if quality == \"Fast\":\n","                    rec_rec = 6 if is_complex else 3\n","                elif quality == \"High precision\":\n","                    rec_rec = 20 if is_complex else 12\n","                else:  # Classic\n","                    rec_rec = 12 if is_complex else 6\n","                num_recycles_eff = max(int(base_recycles), rec_rec)\n","\n","                # Model/pairing recommendations\n","                if is_complex:\n","                    model_type = \"alphafold2_multimer_v3\" if model_type_ui==\"auto\" else model_type_ui\n","                    pair_mode  = \"paired\" if pair_mode_ui==\"auto\" else pair_mode_ui\n","                else:\n","                    model_type = \"alphafold2_ptm\" if model_type_ui==\"auto\" else model_type_ui\n","                    pair_mode  = (\"unpaired\" if strict_mono else (\"unpaired_paired\" if pair_mode_ui==\"auto\" else pair_mode_ui))\n","\n","                # Templates on/off\n","                use_templates_eff = use_templates and (not no_homologs)\n","\n","                info.text(f\"üî¨ {name} ‚Äî model={model_type} ‚Ä¢ MSA={msa_strategy_key} ‚Ä¢ recycles={num_recycles_eff} ‚Ä¢ pair={pair_mode} ‚Ä¢ templates={'ON' if use_templates_eff else 'OFF'}\")\n","                params={\n","                    \"num_models\":num_models,\n","                    \"num_recycles\":num_recycles_eff,\n","                    \"use_amber\":use_amber,\n","                    \"use_templates\":use_templates_eff,\n","                    \"model_type\":model_type,\n","                    \"pair_mode\":pair_mode,\n","                    \"stop_at_score\":(stop_at_score if stop_at_score>0 else None),\n","                    \"msa_strategy\":msa_strategy_key,\n","                    \"jobname_prefix\":safe\n","                }\n","\n","                # Isolated output directory per run + per sequence\n","                seq_hash = hashlib.sha1(seq.encode()).hexdigest()[:8]\n","                out_dir = (run_root / f\"{safe}_{seq_hash}\")\n","                out_dir.mkdir(parents=True, exist_ok=True)\n","\n","                ok, log = run_colabfold_advanced(fa_path, str(out_dir), params, seq_len=seq_len)\n","                job_dir = out_dir\n","                res = analyze_results(job_dir)\n","\n","                if res.get(\"status\")!=\"success\":\n","                    st.info(\"‚õëÔ∏è No PDB/CIF ‚Üí trying last‚Äëchance CPU‚Ä¶\")\n","                    # last-chance: single_sequence minimal\n","                    def last_chance_minirun(fasta_file: str, output_dir: str, job_prefix: str, is_multimer: bool):\n","                        exe = shutil.which(\"colabfold_batch\")\n","                        cmd = [exe or sys.executable, *([] if exe else [\"-m\",\"colabfold.batch\"]), fasta_file, output_dir,\n","                               \"--model-type\", (\"alphafold2_multimer_v3\" if is_multimer else \"alphafold2_ptm\"),\n","                               \"--msa-mode\",\"single_sequence\", \"--num-models\",\"1\",\"--num-recycle\",\"2\",\n","                               \"--pair-mode\",\"paired\" if is_multimer else \"unpaired\", \"--rank\",\"auto\",\"--random-seed\",\"42\",\n","                               \"--disable-unified-memory\",\"--recompile-padding\",\"1\",\n","                               \"--jobname-prefix\", job_prefix, \"--overwrite-existing-results\",\n","                               \"--max-msa\",\"64:64\",\"--disable-cluster-profile\",\"--stop-at-score\",\"70\"]\n","                        env = os.environ.copy(); env.update({\"JAX_PLUGINS\":\"disabled\",\"JAX_PLATFORM_NAME\":\"cpu\",\n","                                                             \"TF_CPP_MIN_LOG_LEVEL\":\"3\",\"XLA_PYTHON_CLIENT_PREALLOCATE\":\"false\",\n","                                                             \"XLA_PYTHON_CLIENT_MEM_FRACTION\":\"0.75\",\"TF_FORCE_GPU_ALLOW_GROWTH\":\"true\"})\n","                        try:\n","                            return _run(cmd, timeout_sec=estimate_msa_timeout(seq_len, \"single_sequence\"), env=env)\n","                        except Exception as e:\n","                            return False, str(e)\n","                    okL, logL = last_chance_minirun(fa_path, str(out_dir), safe, is_complex)\n","                    job_dir = out_dir\n","                    res = analyze_results(job_dir)\n","                    if res.get(\"status\")!=\"success\":\n","                        tail=\"\\n\".join((logL or log or \"\").splitlines()[-120:])\n","                        res[\"message\"]=res.get(\"message\",\"\") + (\"\\n\\n[Last-chance log tail]\\n\"+tail)\n","\n","                # AFDB-first optimized (smart fetch)\n","                if (not is_complex):\n","                    try:\n","                        fetch = smart_afdb_fetch(name, seq)\n","                        if fetch:\n","                            url = fetch.get(\"pdb_url\") or fetch.get(\"cif_url\") or fetch.get(\"bcif_url\")\n","                            if url:\n","                                job_dir = Path(job_dir); job_dir.mkdir(parents=True, exist_ok=True)\n","                                local = job_dir / (safe + \"_AFDB\" + Path(url).suffix)\n","                                if not local.exists():\n","                                    urllib.request.urlretrieve(url, local)\n","                                if local.suffix.lower() in [\".cif\", \".bcif\"]:\n","                                    outp = local.with_suffix(\"\").with_name(local.stem + \"_converted.pdb\")\n","                                    if any_cif_to_pdb(local, outp) or (local.suffix.lower()==\".cif\" and cif_to_pdb_text_cif(local, outp)):\n","                                        pass\n","                                res = analyze_results(job_dir)\n","                    except Exception as e:\n","                        st.info(f\"AFDB‚Äëfirst: {e}\")\n","\n","                results[name]=res\n","                ss.job_dirs[name]=str(job_dir); ss.fasta_paths[name]=fa_path\n","\n","                # Reporting + quality validation\n","                if res.get(\"status\")==\"success\":\n","                    best=(sorted(res[\"models\"], key=lambda m: (m[\"rank\"] if m[\"rank\"] is not None else 9999, -(m[\"avg_plddt\"] or 0))) or [None])[0]\n","                    if best:\n","                        st.success(f\"‚úÖ {name}: best={best['model_id']} (rank={best['rank'] or 'NA'} | pLDDT‚âà{(best['avg_plddt'] or 0):.1f})\")\n","                        warns = validate_prediction({\"avg_plddt\":best.get(\"avg_plddt\"), \"ptm\":best.get(\"ptm\"), \"iptm\":best.get(\"iptm\")})\n","                        for w in warns: st.warning(w)\n","                    else:\n","                        st.success(f\"‚úÖ {name}: structure detected\")\n","                else:\n","                    st.error(f\"‚ùå {name}: {res.get('message','Error')}\")\n","\n","                prog.progress((i+1)/len(valid))\n","            ss.results=results\n","            st.success(\"üéâ Finished ‚Äî check Results / 3D\")\n","\n","# ---------- UI: Results ----------\n","elif current_page == \"üìà Results\":\n","    st.markdown('<div class=\"sub-header\">   Results</div>', unsafe_allow_html=True)\n","    mode = ss.get(\"view_mode\",\"pLDDT (structures)\")\n","\n","    # ===================== STRUCTURES Mode (pLDDT) =====================\n","    if mode.startswith(\"pLDDT\"):\n","        if not ss.get(\"results\"):\n","            st.info(\"No results.\")\n","        else:\n","            st.markdown(\"### üèÜ Comparator (structures)\")\n","            rows=[]\n","            for name,res in ss[\"results\"].items():\n","                if res.get(\"status\")!=\"success\":\n","                    continue\n","                for m in res[\"models\"]:\n","                    rows.append({\n","                        \"Sequence\":name, \"Model\":m[\"model_id\"], \"Rank\":m[\"rank\"], \"RankConf\":m[\"ranking_conf\"],\n","                        \"Avg_pLDDT\":m[\"avg_plddt\"], \"PTM\":m[\"ptm\"], \"ipTM\":m[\"iptm\"],\n","                        \"Format\":m[\"fmt\"].upper(), \"File\":m[\"file\"]\n","                    })\n","            if not rows:\n","                st.warning(\"No model listable.\")\n","            else:\n","                df = pd.DataFrame(rows).sort_values(\n","                    by=[\"Sequence\",\"Rank\",\"Avg_pLDDT\"], ascending=[True,True,False], na_position=\"last\"\n","                )\n","                st.dataframe(df, use_container_width=True, height=320)\n","\n","                if not df.empty:\n","                    st.markdown(\"### üëÅÔ∏è Open a model\")\n","                    idx = st.selectbox(\n","                        \"Model:\", list(range(len(df))),\n","                        format_func=lambda i: f\"{df.iloc[i]['Sequence']} ‚Ä¢ {df.iloc[i]['Model']} ‚Ä¢ {df.iloc[i]['Format']} ‚Ä¢ pLDDT‚âà{(df.iloc[i]['Avg_pLDDT'] or 0):.1f}\",\n","                        index=0\n","                    )\n","                    rec=df.iloc[idx]; path=rec[\"File\"]; fmt=\"cif\" if str(path).lower().endswith((\".cif\",\".bcif\")) else \"pdb\"\n","                    try:\n","                        txt=open(path).read()\n","                        cA, cB, cC, cD = st.columns(4)\n","                        with cA: style = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"cmp_style\")\n","                        with cB: scheme = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"cmp_scheme\")\n","                        with cC: mono = st.checkbox(\"Monomer only\", value=True, key=\"cmp_mono\")\n","                        with cD: first_model_only = st.checkbox(\"1st MODEL only\", value=True, key=\"cmp_firstmodel\")\n","                        chains = list_polymer_chains(path)\n","                        sel_chain = None\n","                        if mono:\n","                            sel_chain = st.selectbox(\"Chain to display\", chains or [\"A\"], index=0, key=\"cmp_chain\")\n","                        if first_model_only:\n","                            txt = keep_first_model_text(fmt, txt)\n","                        html = render_py3d_html(txt, fmt, style, scheme, mono_only=mono, sel_chain=sel_chain)\n","                        html = enhance_py3dmol_html(patch_py3dmol_html(html))\n","                        # HTML stamp to force remount (no key supported by Streamlit 1.28)\n","                        stamp = viewer_key(\"cmp3d\", path=path, style=style, scheme=scheme, mono=mono, chain=sel_chain, first=first_model_only)\n","                        html = apply_viewer_stamp(html, stamp)\n","                        st.components.v1.html(html, height=680)\n","                        st.download_button(\"üì• Download\", data=txt, file_name=Path(path).name,\n","                                           mime=(\"chemical/x-mmcif\" if fmt==\"cif\" else \"chemical/x-pdb\"), use_container_width=True)\n","                        # pLDDT panels\n","                        display_plddt_panels(txt, fmt, label=path, sel_chain=sel_chain if mono else None, key_prefix=\"cmp3d\")\n","                    except Exception as e:\n","                        st.error(f\"Read failed: {e}\")\n","\n","    # ===================== IDENTITY Mode (%) (alignments) =====================\n","    else:\n","        st.markdown(\"### üß¨ Comparator (alignments by Identity)\")\n","\n","        # ---------- Helpers auto (.a3m) ----------\n","        def _find_a3m_files(job_dir: Path):\n","            try:\n","                return sorted(job_dir.rglob(\"*.a3m\"), key=lambda p: p.stat().st_mtime if p.exists() else 0, reverse=True)\n","            except Exception:\n","                return []\n","\n","        def _parse_float(tok: str):\n","            try: return float(str(tok).replace(\"E\",\"e\"))\n","            except Exception: return None\n","\n","        def _parse_int(tok: str):\n","            try: return int(tok)\n","            except Exception: return None\n","\n","        def _parse_id_token(tok: str):\n","            if tok is None: return (None, None)\n","            t = tok.strip().replace(\",\", \"\")\n","            if t.endswith(\"%\"):\n","                try: v = float(t[:-1]); return (v/100.0, v)\n","                except: return (None, None)\n","            try: v = float(t)\n","            except: return (None, None)\n","            if 0.0 <= v <= 1.0: return (v, v*100.0)\n","            if 1.0 < v <= 100.0: return (v/100.0, v)\n","            return (None, None)\n","\n","        def _parse_a3m_file(a3m_path: Path):\n","            if not a3m_path or not a3m_path.exists(): return None\n","            lines = open(a3m_path,\"r\",errors=\"ignore\").read().splitlines()\n","            entries=[]; head=None; seq=[]\n","            for ln in lines:\n","                if ln.startswith(\">\"):\n","                    if head is not None: entries.append((head,\"\".join(seq))); seq=[]\n","                    head=ln[1:].strip()\n","                else:\n","                    seq.append(ln.strip())\n","            if head is not None: entries.append((head,\"\".join(seq)))\n","            if not entries: return None\n","            qh, q_aln = entries[0]\n","            hits=[]\n","            for hdr, aln in entries[1:]:\n","                toks = hdr.split()\n","                acc = toks[0] if toks else hdr\n","                meta = {\"score\": None, \"id_frac\": None, \"id_pct\": None, \"evalue\": None,\n","                        \"q_start\":None,\"q_end\":None,\"q_len\":None,\"t_start\":None,\"t_end\":None,\"t_len\":None}\n","                if len(toks) >= 4:\n","                    sc = _parse_float(toks[1])\n","                    idf, idp = _parse_id_token(toks[2])\n","                    ev = _parse_float(toks[3])\n","                    meta[\"score\"] = sc; meta[\"id_frac\"] = idf; meta[\"id_pct\"] = idp; meta[\"evalue\"] = ev\n","                    if len(toks) >= 10:\n","                        qs = _parse_int(toks[4]); qe=_parse_int(toks[5]); ql=_parse_int(toks[6])\n","                        ts = _parse_int(toks[7]); te=_parse_int(toks[8]); tl=_parse_int(toks[9])\n","                        meta.update({\"q_start\":qs,\"q_end\":qe,\"q_len\":ql,\"t_start\":ts,\"t_end\":te,\"t_len\":tl})\n","                hits.append({\"acc\":acc, \"aln\":aln, \"hdr_meta\":meta})\n","            return {\"query_header\": qh, \"query_aln\": q_aln, \"hits\": hits}\n","\n","        def _reconstruct_a3m_pair(query_aln: str, target_aln: str):\n","            q_line=[]; t_line=[]; iq=0\n","            for ch in target_aln:\n","                if ch.islower():\n","                    t_line.append(ch); q_line.append(\"-\")\n","                else:\n","                    t_line.append(ch)\n","                    q_line.append(query_aln[iq] if iq < len(query_aln) else \"-\"); iq+=1\n","            return \"\".join(q_line), \"\".join(t_line)\n","\n","        def _identity_and_cov(q_line, t_line, q_len):\n","            a=0; n=0; cov_count=0\n","            for q,t in zip(q_line,t_line):\n","                if q!=\"-\":\n","                    cov_count+=1\n","                    if t!=\"-\":\n","                        n+=1; a += (q.upper()==t.upper())\n","            ident = (100.0*a/n) if n>0 else None\n","            cov = round(100.0*cov_count/max(1,q_len), 1) if q_len else None\n","            return ident, cov, n\n","\n","        def _build_auto_from_a3m(name: str, job_dir: Path):\n","            files = _find_a3m_files(job_dir)\n","            if not files: return None\n","            parsed = _parse_a3m_file(files[0])\n","            if not parsed: return None\n","            q_aln = parsed[\"query_aln\"]\n","            q_seq = re.sub(r\"[^A-Za-z]\", \"\", q_aln).upper()\n","            q_len = len(q_seq)\n","            enriched=[]\n","            for h in parsed[\"hits\"]:\n","                q_line, t_line = _reconstruct_a3m_pair(q_aln, h[\"aln\"])\n","                meta = h.get(\"hdr_meta\") or {}\n","                ident_calc, cov_calc, core = _identity_and_cov(q_line, t_line, q_len)\n","                ident_pct = meta.get(\"id_pct\") if meta.get(\"id_pct\") is not None else ((meta[\"id_frac\"]*100.0) if meta.get(\"id_frac\") is not None else ident_calc)\n","                cov = cov_calc\n","                enriched.append({\n","                    \"acc\": h[\"acc\"],\n","                    \"q_line\": q_line, \"t_line\": t_line,\n","                    \"Identity_%\": ident_pct,\n","                    \"Score\": meta.get(\"score\"),\n","                    \"Evalue\": meta.get(\"evalue\"),\n","                    \"Cov_query_%\": cov,\n","                    \"Aligned_core\": core\n","                })\n","            def _val(x,k,default):\n","                v = x.get(k)\n","                if v is None or (isinstance(v,float) and not np.isfinite(v)): return default\n","                return v\n","            enriched = sorted(enriched,\n","                              key=lambda x: (_val(x,\"Identity_%\",-1.0), _val(x,\"Score\",-1.0), -_val(x,\"Evalue\", float(\"+inf\")), _val(x,\"Cov_query_%\",-1.0), _val(x,\"Aligned_core\",-1.0)),\n","                              reverse=True)\n","            return {\"source\":\"auto-a3m\",\"name\":f\"{name} (AUTO)\",\"query_header\":parsed[\"query_header\"],\"query_seq\":q_seq,\"query_len\":q_len,\"hits\":enriched}\n","\n","        # ---------- MANUAL Import ----------\n","        with st.expander(\"üì• Manual import (copy-paste a text block)\", expanded=not ss.get(\"aln_import\")):\n","            sample = \">QueryID\\nSEQUENCE...\\n>UniRef100_E9AV33\\t391\\t0.997\\t8.068E-118\\t0\\t335\\t336\\t0\\t335\\t336\\nMHAGAAAEAA...\\n\"\n","            txt_imp = st.text_area(\"Results block\", height=160, placeholder=sample, key=\"res_imp_text\")\n","            if st.button(\"üîé Analyze & store (manual)\", use_container_width=True, key=\"res_imp_btn\"):\n","                data = parse_custom_text_results(txt_imp)\n","                if not data or not data.get(\"hits\"):\n","                    st.error(\"Block not recognized.\")\n","                else:\n","                    ss.setdefault(\"aln_import\", {})\n","                    ss.aln_import[data[\"name\"]] = data\n","                    st.success(f\"‚úÖ Imported: {data['name']} (hits={len(data['hits'])})\")\n","\n","        # ---------- AUTO Import (.a3m) ----------\n","        with st.expander(\"‚öôÔ∏è Automatic import (.a3m from your predictions)\"):\n","            if not ss.get(\"job_dirs\"):\n","                st.info(\"No prediction job found.\")\n","            else:\n","                seqs_avail = list(ss.job_dirs.keys())\n","                sel_seq = st.selectbox(\"Predicted sequence:\", seqs_avail, index=0, key=\"res_auto_seq\")\n","                job_dir = Path(ss.job_dirs.get(sel_seq,\"\"))\n","                if st.button(\"Build from .a3m\", use_container_width=True, key=\"res_build_a3m\"):\n","                    if not job_dir.exists():\n","                        st.error(\"job_dir not found.\")\n","                    else:\n","                        with st.spinner(\"Building from .a3m‚Ä¶\"):\n","                            ds = _build_auto_from_a3m(sel_seq, job_dir)\n","                        if not ds or not ds.get(\"hits\"):\n","                            st.warning(\"No usable .a3m found for this job.\")\n","                        else:\n","                            ss.setdefault(\"aln_import\", {})\n","                            ss.aln_import[ds[\"name\"]] = ds\n","                            st.success(f\"‚úÖ Automatic import: {ds['name']} (hits={len(ds['hits'])})\")\n","                            try: st.experimental_rerun()\n","                            except Exception: pass\n","\n","        # ---------- Hits table + sorting + non-blocking display ----------\n","        rows=[]; hits_index={}\n","        for name, data in (ss.get(\"aln_import\") or {}).items():\n","            for h in data.get(\"hits\", []):\n","                key=f\"{name}::{h.get('acc','NA')}\"\n","                rows.append({\n","                    \"Sequence\":name,\n","                    \"Accession\":h.get(\"acc\"),\n","                    \"Identity_%\":h.get(\"Identity_%\"),\n","                    \"Score\":h.get(\"Score\"),\n","                    \"Evalue\":h.get(\"Evalue\"),\n","                    \"Cov_query_%\":h.get(\"Cov_query_%\"),\n","                    \"Aligned_core\":h.get(\"Aligned_core\"),\n","                })\n","                hits_index[key]=(name, h, data)\n","\n","        df_hits = pd.DataFrame(rows) if rows else pd.DataFrame(\n","            columns=[\"Sequence\",\"Accession\",\"Identity_%\",\"Score\",\"Evalue\",\"Cov_query_%\",\"Aligned_core\"]\n","        )\n","        if df_hits.empty:\n","            st.info(\"No alignments available.\")\n","        else:\n","            with st.expander(\"‚öôÔ∏è Display options\", expanded=True):\n","                c1, c2, c3 = st.columns(3)\n","                with c1:\n","                    max_rows = st.slider(\"Number of displayed rows (top N)\", 50, 2000, min(300, len(df_hits)), step=50)\n","                with c2:\n","                    enrich = st.checkbox(\"Enrich UniProt/AFDB (can be slow)\", value=False)\n","                with c3:\n","                    sort_field = st.selectbox(\"Sort by\", [\"Identity_%\",\"Score\",\"Evalue\",\"Cov_query_%\",\"Aligned_core\"], index=0)\n","\n","            ascending_map = {\"Evalue\": True}\n","            asc = ascending_map.get(sort_field, False)\n","            df_hits = df_hits.sort_values(by=[sort_field, \"Identity_%\"], ascending=[asc, False], na_position=\"last\")\n","\n","            df_view = df_hits.head(max_rows).reset_index(drop=True)\n","\n","            if enrich:\n","                with st.spinner(\"UniProt/AFDB enrichment‚Ä¶\"):\n","                    df_view = annotate_df_with_uniprot_info(df_view, acc_col=\"Accession\")\n","\n","            try:\n","                st.dataframe(\n","                    df_view, use_container_width=True, height=340,\n","                    column_config={\n","                        \"UniProt_URL\": st.column_config.LinkColumn(\"UniProt_URL\", display_text=\"Open UniProt\"),\n","                        \"AFDB_URL\": st.column_config.LinkColumn(\"AFDB_URL\", display_text=\"Open AFDB\")\n","                    }\n","                )\n","            except Exception:\n","                st.dataframe(df_view, use_container_width=True, height=340)\n","\n","            if enrich and set([\"Accession_UniProt\",\"UniProt_URL\",\"AFDB_URL\"]).issubset(df_view.columns):\n","                try:\n","                    st.markdown(\"UniProt/AFDB links (clickable)\")\n","                    _dfL = df_view[['Accession_UniProt','UniProt_URL','AFDB_URL']].copy()\n","                    _dfL = _dfL[_dfL['Accession_UniProt']!=''].drop_duplicates().head(80)\n","                    st.dataframe(\n","                        _dfL, use_container_width=True, height=180,\n","                        column_config={\n","                            \"UniProt_URL\": st.column_config.LinkColumn(\"UniProt_URL\", display_text=\"Open UniProt\"),\n","                            \"AFDB_URL\": st.column_config.LinkColumn(\"AFDB_URL\", display_text=\"Open AFDB\")\n","                        }\n","                    )\n","                except Exception:\n","                    pass\n","\n","            # Selection based on displayed view\n","            keys_show = [f\"{row['Sequence']}::{row['Accession']}\" for _, row in df_view.iterrows()]\n","            labels_show = [f\"{row['Sequence']} ‚Ä¢ {row['Accession']} ‚Ä¢ Id={(row['Identity_%'] or 0):.1f}%\" for _, row in df_view.iterrows()]\n","            if not keys_show:\n","                st.info(\"No hit displayable (filter too restrictive).\")\n","                st.stop()\n","\n","            sel_idx = st.selectbox(\"Hit:\", list(range(len(keys_show))),\n","                                   format_func=lambda i: labels_show[i], index=0, key=\"id_hits_idx\")\n","            sel_key = keys_show[sel_idx]\n","            dataset, hit, data = hits_index[sel_key]\n","            st.caption(f\"Sequence: {dataset} ‚Ä¢ Hit: {hit.get('acc')} ‚Ä¢ Id={hit.get('Identity_%') or 0:.1f}% ‚Ä¢ Cov={hit.get('Cov_query_%') or 0}%\")\n","\n","            # Alignment text\n","            st.markdown(format_pair_alignment_html(hit.get(\"q_line\",\"\"), hit.get(\"t_line\",\"\")), unsafe_allow_html=True)\n","\n","            # 3D ‚Äî Stacked: Hit (AFDB) ABOVE, Query below\n","            hit_sec = st.container()\n","            query_sec = st.container()\n","\n","            # --- Hit ‚Äî AFDB (top)\n","            with hit_sec:\n","                st.subheader(\"Hit ‚Äî AFDB\")\n","                acc_raw = (hit.get(\"acc\") or \"\").strip()\n","\n","                def _is_uniprot_acc2(x: str):\n","                    return bool(re.fullmatch(r\"[A-Z0-9]{6,10}\", (x or \"\").strip()))\n","\n","                if _is_uniprot_acc2(acc_raw):\n","                    uni_acc = acc_raw\n","                elif acc_raw.startswith(\"UniRef\"):\n","                    with st.spinner(f\"Resolving UniRef ‚Üí UniProt ({acc_raw})‚Ä¶\"):\n","                        uni_acc = resolve_uniref_to_uniprot(acc_raw)\n","                else:\n","                    uni_acc = None\n","\n","                with st.expander(\"‚öôÔ∏è Manual AFDB (if no accession)\", expanded=(uni_acc is None)):\n","                    man = st.text_input(\"UniProt accession (AFDB) or PDB/CIF URL\", value=\"\", key=\"afdb_manual_id_res\")\n","                    if st.button(\"Load (manual)\", key=\"afdb_manual_btn_res\"):\n","                        if man.strip().lower().startswith(\"http\"):\n","                            try:\n","                                tmp = Path(\"/tmp/hit_manual_res\").with_suffix(Path(man).suffix or \".pdb\")\n","                                urllib.request.urlretrieve(man, tmp)\n","                                vpath = tmp\n","                                vfmt = \"pdb\"\n","                                if tmp.suffix.lower() in [\".cif\",\".bcif\"]:\n","                                    out = tmp.with_suffix(\"\").with_name(tmp.stem + \"_converted.pdb\")\n","                                    if any_cif_to_pdb(tmp, out) or (tmp.suffix.lower()==\".cif\" and cif_to_pdb_text_cif(tmp, out)):\n","                                        vpath = out\n","                                a_txt = open(vpath).read()\n","                                c1,c2,c3 = st.columns(3)\n","                                with c1: styleR = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"idh_style_man\")\n","                                with c2: schemeR = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"idh_scheme_man\")\n","                                with c3: firstR = st.checkbox(\"1st MODEL\", value=True, key=\"idh_first_man\")\n","                                chainsR = list_polymer_chains(str(vpath))\n","                                monoR = st.checkbox(\"Monomer only\", value=True, key=\"idh_mono_man\")\n","                                selR = None\n","                                if monoR:\n","                                    selR = st.selectbox(\"Chain\", chainsR or [\"A\"], index=0, key=\"idh_chain_man\")\n","                                if firstR:\n","                                    a_txt = keep_first_model_text(\"pdb\", a_txt)\n","                                htmlH = render_py3d_html(a_txt, vfmt, styleR, schemeR, mono_only=monoR, sel_chain=selR)\n","                                htmlH = enhance_py3dmol_html(patch_py3dmol_html(htmlH))\n","                                stamp = viewer_key(\"idh3d-man\", path=str(vpath), style=styleR, scheme=schemeR, mono=monoR, chain=selR, first=firstR)\n","                                htmlH = apply_viewer_stamp(htmlH, stamp)\n","                                st.components.v1.html(htmlH, height=520)\n","                                display_plddt_panels(a_txt, vfmt, label=str(vpath), sel_chain=selR if monoR else None, key_prefix=\"idh3d-man\")\n","                            except Exception as e:\n","                                st.error(f\"Manual load: {e}\")\n","                        elif _is_uniprot_acc2(man.strip()):\n","                            uni_acc = man.strip()\n","\n","                if uni_acc:\n","                    try:\n","                        fetch = afdb_fetch_by_accession(uni_acc)\n","                        if not fetch:\n","                            st.warning(\"No AFDB model for this hit.\")\n","                        else:\n","                            url = fetch.get(\"pdb_url\") or fetch.get(\"cif_url\") or fetch.get(\"bcif_url\")\n","                            tmp = Path(\"/tmp/afdb_from_hit_res\").with_suffix(Path(url).suffix)\n","                            urllib.request.urlretrieve(url, tmp)\n","                            vpath = tmp\n","                            vfmt = \"pdb\"\n","                            if tmp.suffix.lower() in [\".cif\",\".bcif\"]:\n","                                out = tmp.with_suffix(\"\").with_name(tmp.stem + \"_converted.pdb\")\n","                                if any_cif_to_pdb(tmp, out) or (tmp.suffix.lower()==\".cif\" and cif_to_pdb_text_cif(tmp, out)):\n","                                    vpath = out\n","                            a_txt = open(vpath).read()\n","                            c1,c2,c3 = st.columns(3)\n","                            with c1: styleR = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"idh_style_auto\")\n","                            with c2: schemeR = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"idh_scheme_auto\")\n","                            with c3: firstR = st.checkbox(\"1st MODEL\", value=True, key=\"idh_first_auto\")\n","                            chainsR = list_polymer_chains(str(vpath))\n","                            monoR = st.checkbox(\"Monomer only\", value=True, key=\"idh_mono_auto\")\n","                            selR = None\n","                            if monoR:\n","                                selR = st.selectbox(\"Chain\", chainsR or [\"A\"], index=0, key=\"idh_chain_auto\")\n","                            if firstR:\n","                                a_txt = keep_first_model_text(\"pdb\", a_txt)\n","                            htmlH = render_py3d_html(a_txt, vfmt, styleR, schemeR, mono_only=monoR, sel_chain=selR)\n","                            htmlH = enhance_py3dmol_html(patch_py3dmol_html(htmlH))\n","                            stamp = viewer_key(\"idh3d-auto\", path=str(vpath), style=styleR, scheme=schemeR, mono=monoR, chain=selR, first=firstR)\n","                            htmlH = apply_viewer_stamp(htmlH, stamp)\n","                            st.components.v1.html(htmlH, height=520)\n","                            display_plddt_panels(a_txt, vfmt, label=str(vpath), sel_chain=selR if monoR else None, key_prefix=\"idh3d-auto\")\n","                    except Exception as e:\n","                        st.error(f\"AFDB: {e}\")\n","                elif not st.session_state.get(\"afdb_manual_id_res\"):\n","                    st.info(\"Hit without UniProt accession. Provide an AFDB accession or a PDB/CIF URL above.\")\n","\n","# ---------- UI: 3D Visualization ----------\n","elif current_page == \"üëÅÔ∏è 3D Visualization\":\n","    st.markdown('<div class=\"sub-header\">üëÅÔ∏è 3D Visualization</div>', unsafe_allow_html=True)\n","    mode = ss.get(\"view_mode\",\"pLDDT (structures)\")\n","\n","    # ============ pLDDT: structures ============\n","    if mode.startswith(\"pLDDT\"):\n","        if not ss.results:\n","            st.info(\"No structures.\")\n","        else:\n","            choices=[]\n","            for n,res in ss.results.items():\n","                if res.get(\"status\")!=\"success\": continue\n","                for m in res[\"models\"]:\n","                    choices.append((f\"{n} ‚Ä¢ {m['model_id']} ‚Ä¢ {m['fmt'].upper()} ‚Ä¢ pLDDT‚âà{(m['avg_plddt'] or 0):.1f}\", m))\n","            if not choices:\n","                st.warning(\"No PDB/CIF.\")\n","            else:\n","                idx=st.selectbox(\"Model:\", list(range(len(choices))), format_func=lambda i: choices[i][0], index=0, key=\"v3d_sel\")\n","                m = choices[idx][1]; path=m[\"file\"]; fmt=\"cif\" if path.lower().endswith((\".cif\",\".bcif\")) else \"pdb\"\n","                txt=open(path).read()\n","                c1,c2,c3,c4 = st.columns(4)\n","                with c1: style = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"v3d_style\")\n","                with c2: scheme = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"v3d_scheme\")\n","                with c3: mono = st.checkbox(\"Monomer only\", value=True, key=\"v3d_mono\")\n","                with c4: first_model_only = st.checkbox(\"1st MODEL only\", value=True, key=\"v3d_firstmodel\")\n","                chains = list_polymer_chains(path)\n","                sel_chain = None\n","                if mono:\n","                    sel_chain = st.selectbox(\"Chain\", chains or [\"A\"], index=0, key=\"v3d_chain\")\n","                if first_model_only:\n","                    txt = keep_first_model_text(fmt, txt)\n","                html = render_py3d_html(txt, fmt, style, scheme, mono_only=mono, sel_chain=sel_chain)\n","                html = enhance_py3dmol_html(patch_py3dmol_html(html))\n","                stamp = viewer_key(\"v3d\", path=path, style=style, scheme=scheme, mono=mono, chain=sel_chain, first=first_model_only)\n","                html = apply_viewer_stamp(html, stamp)\n","                st.components.v1.html(html, height=680)\n","                st.download_button(\"üì• Download\", data=txt, file_name=Path(path).name,\n","                                   mime=(\"chemical/x-mmcif\" if fmt==\"cif\" else \"chemical/x-pdb\"),\n","                                   use_container_width=True)\n","                # pLDDT panels\n","                display_plddt_panels(txt, fmt, label=path, sel_chain=sel_chain if mono else None, key_prefix=\"v3d\")\n","\n","    # ============ Identity: Query vs AFDB ============\n","    else:\n","        rows=[]; idxmap={}\n","        for name, data in (ss.get(\"aln_import\") or {}).items():\n","            for h in data.get(\"hits\", []):\n","                key=f\"{name}::{h.get('acc','NA')}\"\n","                rows.append({\"Sequence\":name,\"Accession\":h.get(\"acc\"),\"Identity_%\":h.get(\"Identity_%\"),\"Cov_query_%\":h.get(\"Cov_query_%\")})\n","                idxmap[key]=(name,h,data)\n","        df = pd.DataFrame(rows).sort_values(by=[\"Identity_%\",\"Cov_query_%\"], ascending=[False,False]) if rows else pd.DataFrame()\n","\n","        if df.empty:\n","            st.info(\"No imported alignments. Go to Results (Identity Mode) to import or build automatically.\")\n","        else:\n","            # Add clickable UniProt/AFDB columns\n","            df = annotate_df_with_uniprot_info(df, acc_col=\"Accession\")\n","            try:\n","                st.dataframe(\n","                    df, use_container_width=True, height=260,\n","                    column_config={\n","                        \"UniProt_URL\": st.column_config.LinkColumn(\"UniProt_URL\", display_text=\"Open UniProt\"),\n","                        \"AFDB_URL\": st.column_config.LinkColumn(\"AFDB_URL\", display_text=\"Open AFDB\")\n","                    }\n","                )\n","            except Exception:\n","                st.dataframe(df, use_container_width=True, height=260)\n","\n","            keys = list(idxmap.keys())\n","            sel = st.selectbox(\"Hit:\", keys, index=0,\n","                               format_func=lambda k: f\"{k.split('::')[0]} ‚Ä¢ {k.split('::')[-1]} ‚Ä¢ Id={df.iloc[keys.index(k)]['Identity_%']:.1f}%\", key=\"id3d_sel\")\n","\n","            seq_name, hit, data = idxmap[sel]\n","\n","            colL, colR = st.columns(2)\n","            # Query\n","            with colL:\n","                st.subheader(\"Query ‚Äî best model\")\n","                q_path, q_fmt, q_best = get_best_query_model(ss, seq_name)\n","                if not q_path:\n","                    avail = [k for k,v in (ss.get(\"results\") or {}).items() if v.get(\"status\")==\"success\"]\n","                    if avail:\n","                        st.info(\"Associate with an existing predicted sequence:\")\n","                        sel_q = st.selectbox(\"Associate with:\", avail, index=0, key=\"id3d_q_assoc\")\n","                        q_path, q_fmt, q_best = get_best_query_model(ss, sel_q)\n","                    else:\n","                        st.info(\"No ColabFold model for this sequence.\")\n","                if q_path:\n","                    q_txt = open(q_path).read()\n","                    c1,c2,c3 = st.columns(3)\n","                    with c1: styleL = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"id3d_q_style\")\n","                    with c2: schemeL = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"id3d_q_scheme\")\n","                    with c3: firstL = st.checkbox(\"1st MODEL\", value=True, key=\"id3d_q_first\")\n","                    chainsL = list_polymer_chains(q_path)\n","                    monoL = st.checkbox(\"Monomer only\", value=True, key=\"id3d_q_mono\")\n","                    selL = None\n","                    if monoL:\n","                        selL = st.selectbox(\"Chain\", chainsL or [\"A\"], index=0, key=\"id3d_q_chain\")\n","                    if firstL:\n","                        q_txt = keep_first_model_text(q_fmt, q_txt)\n","                    htmlQ = render_py3d_html(q_txt, q_fmt, styleL, schemeL, mono_only=monoL, sel_chain=selL)\n","                    htmlQ = enhance_py3dmol_html(patch_py3dmol_html(htmlQ))\n","                    stamp = viewer_key(\"id3d-q\", path=q_path, style=styleL, scheme=schemeL, mono=monoL, chain=selL, first=firstL)\n","                    htmlQ = apply_viewer_stamp(htmlQ, stamp)\n","                    st.components.v1.html(htmlQ, height=520)\n","                    display_plddt_panels(q_txt, q_fmt, label=q_path, sel_chain=selL if monoL else None, key_prefix=\"id3d-q\")\n","\n","            # Hit (AFDB) with UniRef/manual resolver\n","            with colR:\n","                st.subheader(\"Hit ‚Äî AFDB\")\n","                acc_raw = (hit.get(\"acc\") or \"\").strip()\n","                uni_acc = acc_raw if _is_uniprot_acc(acc_raw) else (resolve_uniref_to_uniprot(acc_raw) if acc_raw.startswith(\"UniRef\") else None)\n","\n","                with st.expander(\"‚öôÔ∏è Manual AFDB (if no accession)\", expanded=(uni_acc is None)):\n","                    man = st.text_input(\"UniProt accession (AFDB) or PDB/CIF URL\", value=\"\", key=\"afdb_manual_id_v3d\")\n","                    if st.button(\"Load (manual)\", key=\"afdb_manual_btn_v3d\"):\n","                        if man.strip().lower().startswith(\"http\"):\n","                            try:\n","                                tmp = Path(\"/tmp/afdb_manual_v3d\").with_suffix(Path(man).suffix or \".pdb\")\n","                                urllib.request.urlretrieve(man, tmp)\n","                                vpath = tmp\n","                                vfmt = \"pdb\"\n","                                if tmp.suffix.lower() in [\".cif\",\".bcif\"]:\n","                                    out = tmp.with_suffix(\"\").with_name(tmp.stem + \"_converted.pdb\")\n","                                    if any_cif_to_pdb(tmp, out) or (tmp.suffix.lower()==\".cif\" and cif_to_pdb_text_cif(tmp, out)):\n","                                        vpath = out\n","                                a_txt = open(vpath).read()\n","                                c1,c2,c3 = st.columns(3)\n","                                with c1: styleR = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"idh_style_v3d_man\")\n","                                with c2: schemeR = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"idh_scheme_v3d_man\")\n","                                with c3: firstR = st.checkbox(\"1st MODEL\", value=True, key=\"idh_first_v3d_man\")\n","                                chainsR = list_polymer_chains(str(vpath))\n","                                monoR = st.checkbox(\"Monomer only\", value=True, key=\"idh_mono_v3d_man\")\n","                                selR = None\n","                                if monoR:\n","                                    selR = st.selectbox(\"Chain\", chainsR or [\"A\"], index=0, key=\"idh_chain_v3d_man\")\n","                                if firstR:\n","                                    a_txt = keep_first_model_text(\"pdb\", a_txt)\n","                                htmlH = render_py3d_html(a_txt, vfmt, styleR, schemeR, mono_only=monoR, sel_chain=selR)\n","                                htmlH = enhance_py3dmol_html(patch_py3dmol_html(htmlH))\n","                                stamp = viewer_key(\"id3d-hit-man\", path=str(vpath), style=styleR, scheme=schemeR, mono=monoR, chain=selR, first=firstR)\n","                                htmlH = apply_viewer_stamp(htmlH, stamp)\n","                                st.components.v1.html(htmlH, height=520)\n","                                display_plddt_panels(a_txt, vfmt, label=str(vpath), sel_chain=selR if monoR else None, key_prefix=\"id3d-hit-man\")\n","                            except Exception as e:\n","                                st.error(f\"Manual load: {e}\")\n","                        elif _is_uniprot_acc(man.strip()):\n","                            uni_acc = man.strip()\n","\n","                if uni_acc:\n","                    try:\n","                        fetch = afdb_fetch_by_accession(uni_acc)\n","                        if not fetch:\n","                            st.warning(\"No AFDB model for this hit.\")\n","                        else:\n","                            url = fetch.get(\"pdb_url\") or fetch.get(\"cif_url\") or fetch.get(\"bcif_url\")\n","                            tmp = Path(\"/tmp/afdb_v3d\").with_suffix(Path(url).suffix)\n","                            urllib.request.urlretrieve(url, tmp)\n","                            vpath = tmp\n","                            vfmt = \"pdb\"\n","                            if tmp.suffix.lower() in [\".cif\",\".bcif\"]:\n","                                out = tmp.with_suffix(\"\").with_name(tmp.stem + \"_converted.pdb\")\n","                                if any_cif_to_pdb(tmp, out) or (tmp.suffix.lower()==\".cif\" and cif_to_pdb_text_cif(tmp, out)):\n","                                    vpath = out\n","                            a_txt = open(vpath).read()\n","                            c1,c2,c3 = st.columns(3)\n","                            with c1: styleR = st.selectbox(\"Style\", [\"Cartoon\",\"Stick\",\"Sphere\",\"Line\",\"Surface\"], 0, key=\"idh_style_v3d_auto\")\n","                            with c2: schemeR = st.selectbox(\"Color\", [\"pLDDT (B-factor)\",\"Spectrum\",\"Chain\"], 0, key=\"idh_scheme_v3d_auto\")\n","                            with c3: firstR = st.checkbox(\"1st MODEL\", value=True, key=\"idh_first_v3d_auto\")\n","                            chainsR = list_polymer_chains(str(vpath))\n","                            monoR = st.checkbox(\"Monomer only\", value=True, key=\"idh_mono_v3d_auto\")\n","                            selR = None\n","                            if monoR:\n","                                selR = st.selectbox(\"Chain\", chainsR or [\"A\"], index=0, key=\"idh_chain_v3d_auto\")\n","                            if firstR:\n","                                a_txt = keep_first_model_text(\"pdb\", a_txt)\n","                            htmlH = render_py3d_html(a_txt, vfmt, styleR, schemeR, mono_only=monoR, sel_chain=selR)\n","                            htmlH = enhance_py3dmol_html(patch_py3dmol_html(htmlH))\n","                            stamp = viewer_key(\"id3d-hit-auto\", path=str(vpath), style=styleR, scheme=schemeR, mono=monoR, chain=selR, first=firstR)\n","                            htmlH = apply_viewer_stamp(htmlH, stamp)\n","                            st.components.v1.html(htmlH, height=520)\n","                            display_plddt_panels(a_txt, vfmt, label=str(vpath), sel_chain=selR if monoR else None, key_prefix=\"id3d-hit-auto\")\n","                    except Exception as e:\n","                        st.error(f\"AFDB: {e}\")\n","                elif not st.session_state.get(\"afdb_manual_id_v3d\"):\n","                    st.info(\"Hit without UniProt accession. Provide an AFDB accession or a PDB/CIF URL above.\")\n","\n","# ---------- UI: Settings ----------\n","elif current_page == \"‚öôÔ∏è Settings\":\n","    st.markdown('<div class=\"sub-header\">‚öôÔ∏è Settings & System</div>', unsafe_allow_html=True)\n","    c1, c2 = st.columns(2)\n","    with c1:\n","        try:\n","            st.metric(\"CPU Cores\", psutil.cpu_count())\n","            st.metric(\"Total RAM\", f\"{psutil.virtual_memory().total/(1024**3):.1f} GB\")\n","        except Exception:\n","            st.warning(\"CPU/RAM info unavailable.\")\n","        try:\n","            r = subprocess.run([\"nvidia-smi\",\"--query-gpu=name\",\"--format=csv,noheader\"], capture_output=True, text=True)\n","            gpu = r.stdout.strip().split(\"\\n\")[0] if r.returncode==0 and r.stdout.strip() else \"Not detected\"\n","        except Exception:\n","            gpu = \"Not detected\"\n","        st.metric(\"GPU\", gpu)\n","    with c2:\n","        try:\n","            import jax\n","            st.caption(f\"JAX backend: {jax.default_backend()} | devices: {jax.devices()}\")\n","        except Exception:\n","            st.caption(\"JAX backend: unknown\")\n","# ---------- Footer ----------\n","st.markdown(\"---\")\n","st.markdown('<div style=\"text-align:center;color:#666;padding:0.8rem 0;\">üß¨ AlphaFold Fusion Premium ‚Äî AF Fidelity ‚Üë + pLDDT/Identity + AFDB + Reliable 3D</div>', unsafe_allow_html=True)\n","'''\n","\n","# Write app.py\n","with open(\"app.py\",\"w\",encoding=\"utf-8\") as f:\n","    f.write(app_code)\n","print(\"‚úÖ app.py written.\")\n","\n","# Config Streamlit\n","os.makedirs(\".streamlit\", exist_ok=True)\n","with open(\".streamlit/config.toml\",\"w\",encoding=\"utf-8\") as f:\n","    f.write(\"\"\"\n","[server]\n","headless = true\n","address = \"0.0.0.0\"\n","port = 8501\n","enableCORS = false\n","enableXsrfProtection = false\n","[browser]\n","gatherUsageStats = false\n","[theme]\n","primaryColor = \"#4361ee\"\n","backgroundColor = \"#ffffff\"\n","secondaryBackgroundColor = \"#f8f9fa\"\n","textColor = \"#212529\"\n","font = \"sans serif\"\n","\"\"\")\n","\n","# Launch Streamlit\n","print(\"üöÄ Starting the Streamlit application‚Ä¶\")\n","proc = subprocess.Popen(\n","    [sys.executable,\"-m\",\"streamlit\",\"run\",\"app.py\",\"--server.port\",\"8501\",\"--server.address\",\"0.0.0.0\"],\n","    stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT\n",")\n","time.sleep(12)\n","\n","# URL Colab + fallback Cloudflared\n","try:\n","    from google.colab import output\n","    from IPython.display import HTML, display\n","    public_url = output.eval_js(\"google.colab.kernel.proxyPort(8501)\")\n","    print(\"\\nüéâ Interface ready !\"); print(f\"üåê URL : {public_url}\")\n","    display(HTML(f\"\"\"\n","    <div style=\"padding:24px;border-radius:16px;background:linear-gradient(135deg,#4361ee 0%,#3a0ca3 100%);text-align:center;color:#fff;margin-top:16px;\">\n","      <h2 style=\"margin-bottom:12px;\">üß¨ AlphaFold Fusion Premium</h2>\n","      <a href=\"{public_url}\" target=\"_blank\" style=\"display:inline-block;padding:14px 26px;background:#ff6b6b;border-radius:12px;color:white;text-decoration:none;font-weight:bold;\">OPEN INTERFACE</a>\n","      <p style=\"margin-top:10px;font-family:monospace;\">{public_url}</p>\n","    </div>\"\"\"))\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Colab proxy unavailable: {e}\")\n","    try:\n","        print(\"üåê Cloudflared attempt‚Ä¶\")\n","        bin_path=\"/usr/local/bin/cloudflared\"\n","        if not Path(bin_path).exists():\n","            url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"\n","            subprocess.run([\"wget\",\"-q\",\"-O\", bin_path, url], check=False)\n","            os.chmod(bin_path,0o755)\n","        proc_cf = subprocess.Popen(\n","            [bin_path,\"tunnel\",\"--url\",\"http://127.0.0.1:8501\",\"--no-autoupdate\"],\n","            stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1\n","        )\n","        tunnel_url=None; t0=time.time(); import re as _re\n","        while time.time()-t0<90:\n","            line=proc_cf.stdout.readline()\n","            if not line:\n","                time.sleep(0.2); continue\n","            m=_re.search(r\"https://[-\\w]+\\.trycloudflare\\.com\", line)\n","            if m:\n","                tunnel_url=m.group(0); break\n","        if tunnel_url:\n","            print(\"üéâ Cloudflared tunnel :\", tunnel_url)\n","            from IPython.display import HTML, display\n","            display(HTML(f\"\"\"\n","            <div style=\"padding:24px;border-radius:16px;background:#0ea5e9;text-align:center;color:#fff;margin-top:16px;\">\n","              <h2 style=\"margin-bottom:12px;\">üß¨ AlphaFold Fusion Premium</h2>\n","              <a href=\"{tunnel_url}\" target=\"_blank\" style=\"display:inline-block;padding:14px 26px;background:#111827;border-radius:12px;color:white;text-decoration:none;font-weight:bold;\">OPEN (Cloudflared)</a>\n","              <p style=\"margin-top:10px;font-family:monospace;\">{tunnel_url}</p>\n","            </div>\"\"\"))\n","        else:\n","            print(\"‚ùå No Cloudflared URL. If local: http://localhost:8501\")\n","    except Exception as e2:\n","        print(\"‚ùå Cloudflared failed:\", e2)\n","        print(\"If local: http://localhost:8501\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":690},"id":"rPZ-HM4LudUV","executionInfo":{"status":"ok","timestamp":1766569756924,"user_tz":-60,"elapsed":185093,"user":{"displayName":"","userId":""}},"outputId":"ad7daa11-fcc9-4525-a75a-d5ccb956e05e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üß¨ AlphaFold Premium ‚Äî AF fidelity ‚Üë (MSA/Multimer/Recycles) + pLDDT + Identity + AFDB-first + Reliable 3D\n","================================================================================\n","  ‚Üí colabfold[alphafold]\n","    ‚Üí pip colabfold[alphafold] @ https://codeload.github.com/sokrypton/ColabFold/zip/refs/heads/main\n","    ‚Üí pip numpy==1.26.4\n","    ‚Üí pip pandas>=2,<3\n","    ‚Üí pip tensorflow==2.18.* protobuf>=4.25,<6\n","    ‚Üí pip streamlit==1.28.0\n","    ‚Üí pip plotly==5.17.0\n","    ‚Üí pip py3Dmol==2.1.0\n","    ‚Üí pip biopython>=1.83,<2\n","    ‚Üí pip Pillow==10.1.0\n","    ‚Üí pip psutil==5.9.8\n","    ‚Üí pip gemmi==0.6.6\n","    ‚Üí pip jax>=0.5.0,<0.6 jaxlib>=0.5.0,<0.6\n","üîß detected jaxlib: 0.5.3\n","    ‚Üí pip jax-cuda12-plugin==0.5.3\n","‚úÖ JAX ready ‚Äî backend: gpu | devices: [CudaDevice(id=0)]\n","‚ö†Ô∏è NumPy/Pandas/TF import failed: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n","‚úÖ Dependencies installed\n","================================================================================\n","‚úÖ app.py written.\n","üöÄ Starting the Streamlit application‚Ä¶\n","\n","üéâ Interface ready !\n","üåê URL : https://8501-gpu-t4-s-11m6er7faugg1-c.asia-southeast1-1.prod.colab.dev\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div style=\"padding:24px;border-radius:16px;background:linear-gradient(135deg,#4361ee 0%,#3a0ca3 100%);text-align:center;color:#fff;margin-top:16px;\">\n","      <h2 style=\"margin-bottom:12px;\">üß¨ AlphaFold Fusion Premium</h2>\n","      <a href=\"https://8501-gpu-t4-s-11m6er7faugg1-c.asia-southeast1-1.prod.colab.dev\" target=\"_blank\" style=\"display:inline-block;padding:14px 26px;background:#ff6b6b;border-radius:12px;color:white;text-decoration:none;font-weight:bold;\">OPEN INTERFACE</a>\n","      <p style=\"margin-top:10px;font-family:monospace;\">https://8501-gpu-t4-s-11m6er7faugg1-c.asia-southeast1-1.prod.colab.dev</p>\n","    </div>"]},"metadata":{}}]},{"cell_type":"code","source":["# PATCH TOUT-EN-UN ‚Äî Corrig√© (ss non d√©fini) + viewers verticaux + correctifs (idempotent)\n","\n","import os, sys, re, time, subprocess, textwrap\n","from pathlib import Path\n","\n","# 0) Stop serveurs\n","os.system(\"pkill -f streamlit 2>/dev/null || true\")\n","os.system(\"pkill -f cloudflared 2>/dev/null || true\")\n","\n","# 1) Deps minimales\n","def pip_install(pkgs):\n","    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-cache-dir\"] + pkgs\n","    print(\"‚Üí pip\", \" \".join(pkgs))\n","    r = subprocess.run(cmd, check=False, text=True, capture_output=True)\n","    if r.returncode != 0:\n","        print(r.stdout[-2000:])\n","        print(r.stderr[-2000:])\n","    return r.returncode == 0\n","\n","subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"], check=False)\n","pip_install([\"streamlit==1.28.0\"]) or pip_install([\"streamlit\"])\n","for pkg in [\"plotly==5.17.0\", \"py3Dmol==2.1.0\", \"numpy==1.26.4\"]:\n","    pip_install([pkg])\n","\n","# 2) Charger app.py\n","app_path = Path(\"app.py\")\n","if not app_path.exists():\n","    raise FileNotFoundError(\"app.py introuvable. Ex√©cute d'abord le script original.\")\n","src = app_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n","try: Path(\"app.py.bak_allinone_fix\").write_text(src, encoding=\"utf-8\")\n","except: pass\n","\n","changed = False\n","\n","# 3) Import quote (robuste)\n","if \"from urllib.parse import quote\" not in src:\n","    src = src.replace(\"import streamlit as st\", \"import streamlit as st\\nfrom urllib.parse import quote\")\n","    changed = True\n","\n","# 4) Corriger le NameError: remplacer ss.setdefault(...) positionn√© AVANT l'initialisation par st.session_state.setdefault(...)\n","pos_ss = src.find(\"ss=st.session_state\")\n","if pos_ss != -1:\n","    head = src[:pos_ss]\n","    head2 = head.replace(\"ss.setdefault(\", \"st.session_state.setdefault(\")\n","    # Optionnel: st.session_state[\"...\"] √† la place de ss[\"...\"] si pr√©sent avant\n","    head2 = re.sub(r'\\bss\\[(.+?)\\]', r'st.session_state[\\1]', head2)\n","    if head2 != head:\n","        src = head2 + src[pos_ss:]\n","        changed = True\n","\n","# 5) Fallback Home si page inconnue (s√ªr)\n","if 'current_page = ss.get(\"nav_page\", \"üè† Home\")' in src and \"PAGES_SET = {\" not in src:\n","    src = src.replace(\n","        'current_page = ss.get(\"nav_page\", \"üè† Home\")',\n","        'current_page = ss.get(\"nav_page\", \"üè† Home\")\\n'\n","        'PAGES_SET = {\"üè† Home\",\"üìä Predictions\",\"üìà Results\",\"üëÅÔ∏è 3D Visualization\",\"‚öôÔ∏è Settings\"}\\n'\n","        'if current_page not in PAGES_SET:\\n'\n","        '    st.session_state[\"nav_page\"] = \"üè† Home\"\\n'\n","        '    current_page = \"üè† Home\"'\n","    )\n","    changed = True\n","\n","# 6) Column config: labels + Voir_3D_URL + virgules (idempotent)\n","def fix_column_config_block(m):\n","    b = m.group(0)\n","    b = b.replace(\n","        'st.column_config.LinkColumn(\"UniProt_URL\", display_text=\"Open UniProt\")',\n","        'st.column_config.LinkColumn(\"UniProt_URL\", display_text=\"UniProt (onglet)\")'\n","    ).replace(\n","        'st.column_config.LinkColumn(\"AFDB_URL\", display_text=\"Open AFDB\")',\n","        'st.column_config.LinkColumn(\"AFDB_URL\", display_text=\"AFDB (onglet)\")'\n","    )\n","    lines = b.splitlines()\n","    def ends_with_comma(s): return s.rstrip().endswith(\",\")\n","    def ensure_trailing_comma(i):\n","        lines[i] = lines[i].rstrip()\n","        if not ends_with_comma(lines[i]): lines[i] += \",\"\n","    for i, ln in enumerate(lines):\n","        if re.search(r'^\\s*\"UniProt_URL\"\\s*:\\s*st\\.column_config\\.LinkColumn\\(', ln): ensure_trailing_comma(i)\n","        if re.search(r'^\\s*\"AFDB_URL\"\\s*:\\s*st\\.column_config\\.LinkColumn\\(', ln): ensure_trailing_comma(i)\n","    if not any('\"Voir_3D_URL\"' in ln for ln in lines):\n","        close_idx = None\n","        for i in range(len(lines)-1, -1, -1):\n","            if lines[i].strip() == \"}\": close_idx = i; break\n","        if close_idx is not None:\n","            indent = re.match(r'^(\\s*)', lines[close_idx]).group(1)\n","            prev = close_idx - 1\n","            while prev >= 0 and lines[prev].strip() == \"\": prev -= 1\n","            if prev >= 0 and lines[prev].strip() != \"{\": ensure_trailing_comma(prev)\n","            lines.insert(close_idx, f'{indent}\"Voir_3D_URL\": st.column_config.LinkColumn(\"Voir_3D_URL\", display_text=\"Voir 3D\"),')\n","    b2 = \"\\n\".join(lines)\n","    b2 = re.sub(r',\\s*,', ',', b2)\n","    return b2\n","new_src = re.sub(r'column_config\\s*=\\s*\\{[\\s\\S]*?\\}', fix_column_config_block, src)\n","if new_src != src:\n","    src = new_src\n","    changed = True\n","\n","# 7) annotate_df_with_uniprot_info ‚Üí Voir_3D_URL (idempotent)\n","if \"def annotate_df_with_uniprot_info(\" in src and \"Voir_3D_URL\" not in src:\n","    src = re.sub(\n","        r'(def\\s+annotate_df_with_uniprot_info\\(.*?\\):)([\\s\\S]*?)(?=\\n\\s*def\\s|\\n#\\s*-{2,}\\s*PDB/CIF|\\Z)',\n","        textwrap.dedent('''\n","        def annotate_df_with_uniprot_info(df, acc_col=\"Accession\",\n","                                          col_up=\"Accession_UniProt\", col_name=\"UniProt_Name\",\n","                                          col_uniprot_url=\"UniProt_URL\", col_afdb_url=\"AFDB_URL\", timeout=8):\n","            try:\n","                if df is None or df.empty or acc_col not in df.columns: return df\n","                vals = df[acc_col].astype(str).tolist()\n","                uniq = sorted(set(v for v in vals if v))\n","                mp_up, mp_nm, mp_u, mp_a, mp_v = {}, {}, {}, {}, {}\n","                for a in uniq:\n","                    if a in ss[\"_acc_to_uniprot_cache\"]:\n","                        up = ss[\"_acc_to_uniprot_cache\"][a]\n","                    else:\n","                        up = resolve_accession_to_uniprot(a, timeout=timeout)\n","                        ss[\"_acc_to_uniprot_cache\"][a] = up\n","                    nm = get_uniprot_name_from_uniprot(up, timeout=timeout) if up else \"\"\n","                    mp_up[a] = up or \"\"; mp_nm[a] = nm or \"\"\n","                    mp_u[a]  = (f\"https://www.uniprot.org/uniprotkb/{up}\" if up else \"\")\n","                    mp_a[a]  = (f\"https://alphafold.ebi.ac.uk/entry/{up}\" if up else \"\")\n","                    try:\n","                        vabs = build_abs_viewer_url_from_uniprot_acc(up) if up else \"\"\n","                    except Exception:\n","                        vabs = \"\"\n","                    mp_v[a]  = vabs\n","                s_up = df[acc_col].map(lambda x: mp_up.get(str(x), \"\"))\n","                s_nm = df[acc_col].map(lambda x: mp_nm.get(str(x), \"\"))\n","                s_u  = df[acc_col].map(lambda x: mp_u.get(str(x),  \"\"))\n","                s_a  = df[acc_col].map(lambda x: mp_a.get(str(x),  \"\"))\n","                s_v  = df[acc_col].map(lambda x: mp_v.get(str(x),  \"\"))\n","                def _ins(col, ser, after):\n","                    if col in df.columns: df[col] = ser\n","                    else:\n","                        pos = list(df.columns).index(after)+1 if after in df.columns else len(df.columns)\n","                        df.insert(pos, col, ser)\n","                _ins(col_up, s_up, acc_col)\n","                _ins(col_name, s_nm, col_up)\n","                _ins(col_uniprot_url, s_u, col_name)\n","                _ins(col_afdb_url, s_a, col_uniprot_url)\n","                _ins(\"Voir_3D_URL\", s_v, col_afdb_url)\n","                return df\n","            except Exception:\n","                return df\n","        ''').strip(\"\\n\"),\n","        src, count=1, flags=re.MULTILINE\n","    )\n","    changed = True\n","\n","# 8) Deep-link + URLs absolues (si absents)\n","if \"build_abs_viewer_url_from_uniprot_acc\" not in src:\n","    utils_pos = src.find(\"# ---------- Utils\")\n","    qp_block = textwrap.dedent('''\n","    # ---------- Query params: deep-link vers viewer + auto-load AFDB/URL ----------\n","    PAGE_KEYS = {\n","        \"home\": \"üè† Home\",\n","        \"predict\": \"üìä Predictions\",\n","        \"results\": \"üìà Results\",\n","        \"viewer\": \"üëÅÔ∏è 3D Visualization\",\n","        \"settings\": \"‚öôÔ∏è Settings\",\n","    }\n","\n","    def _qp_first(qp: dict, key: str):\n","        v = qp.get(key)\n","        if isinstance(v, list): return v[0] if v else None\n","        return v\n","\n","    def apply_query_params_to_session():\n","        try:\n","            qp = st.experimental_get_query_params()\n","        except Exception:\n","            return\n","        page = (_qp_first(qp, \"page\") or \"\").strip().lower()\n","        mode = (_qp_first(qp, \"mode\") or \"\").strip().lower()  # plddt | identity\n","        afdb = (_qp_first(qp, \"afdb\") or \"\").strip()\n","        url  = (_qp_first(qp, \"url\")  or \"\").strip()\n","        if page in PAGE_KEYS: st.session_state[\"nav_page\"] = PAGE_KEYS[page]\n","        if mode == \"plddt\": st.session_state[\"view_mode\"] = \"pLDDT (structures)\"\n","        elif mode == \"identity\": st.session_state[\"view_mode\"] = \"Identity (%) (alignments)\"\n","        if afdb or url:\n","            token = hashlib.sha1(f\"{afdb}|{url}\".encode(\"utf-8\",\"ignore\")).hexdigest()[:12]\n","            if st.session_state.get(\"_autoload_token\") != token:\n","                st.session_state[\"_autoload_token\"] = token\n","                st.session_state[\"_autoload_structure\"] = {\"afdb\": afdb or None, \"url\": url or None}\n","\n","    apply_query_params_to_session()\n","\n","    def build_viewer_url_from_uniprot_acc(up_acc: str) -> str:\n","        up_acc = (up_acc or \"\").strip()\n","        if not up_acc: return \"\"\n","        return f\"?page=viewer&mode=plddt&afdb={quote(up_acc)}\"\n","\n","    def build_viewer_url_from_any_url(url: str) -> str:\n","        url = (url or \"\").strip()\n","        if not url: return \"\"\n","        return f\"?page=viewer&mode=plddt&url={quote(url)}\"\n","\n","    # ---------- Base URL (liens absolus) ----------\n","    def get_app_base_url() -> str:\n","        import os\n","        from pathlib import Path\n","        for k in (\"APP_PUBLIC_URL\",\"PUBLIC_URL\",\"STREAMLIT_PUBLIC_URL\",\"CF_PUBLIC_URL\"):\n","            v = os.environ.get(k)\n","            if v: return v.rstrip(\"/\")\n","        try:\n","            p = Path(__file__).resolve().parent / \"public_url.txt\"\n","            if p.exists():\n","                v = p.read_text(encoding=\"utf-8\").strip()\n","                if v: return v.rstrip(\"/\")\n","        except Exception:\n","            pass\n","        return \"http://localhost:8501\"\n","\n","    def build_abs_viewer_url_from_uniprot_acc(up_acc: str) -> str:\n","        rel = build_viewer_url_from_uniprot_acc(up_acc)\n","        base = get_app_base_url()\n","        if rel and base: return f\"{base}{rel}\"\n","        return f\"https://alphafold.ebi.ac.uk/entry/{up_acc}\" if up_acc else \"\"\n","\n","    def build_abs_viewer_url_from_any_url(url: str) -> str:\n","        rel = build_viewer_url_from_any_url(url)\n","        base = get_app_base_url()\n","        if rel and base: return f\"{base}{rel}\"\n","        return url or \"\"\n","    ''').strip(\"\\n\")\n","    if utils_pos != -1:\n","        src = src[:utils_pos] + qp_block + \"\\n\\n\" + src[utils_pos:]\n","    else:\n","        src += \"\\n\\n\" + qp_block + \"\\n\"\n","    changed = True\n","else:\n","    src = src.replace('return f\"{base}/{rel.lstrip(\\'?\\')}\"', 'return f\"{base}{rel}\"')\n","\n","# 9) Checkbox pLDDT: cl√© unique\n","src_new = src.replace(\n","    'st.checkbox(\"Show pLDDT legend\", value=True)',\n","    'st.checkbox(\"Show pLDDT legend\", value=True, key=f\"{key_prefix}_legend\")'\n",")\n","if src_new != src:\n","    src = src_new; changed = True\n","\n","# 10) --jobname\n","if \"--jobname-prefix\" in src:\n","    src = src.replace(\"--jobname-prefix\", \"--jobname\"); changed = True\n","\n","# 11) Anti-doublons PDB/CIF apr√®s conversion\n","src_new = re.sub(\n","    r'(pdbs\\s*=\\s*sorted\\(converted,\\s*key=lambda\\s+x:x\\.stat\\(\\)\\.st_mtime\\)\\s*)\\n',\n","    r'\\1\\n        cifs = []\\n',\n","    src\n",")\n","if src_new != src:\n","    src = src_new; changed = True\n","\n","# 12) APIs stables\n","if \"st.experimental_rerun()\" in src or \"st.experimental_set_query_params()\" in src:\n","    src = src.replace(\"st.experimental_rerun()\", \"st.rerun()\")\n","    src = src.replace(\"st.experimental_set_query_params()\", \"st.query_params.clear()\")\n","    changed = True\n","\n","# 13) Helpers Domaines (si absents)\n","if \"render_domains_py3d_html\" not in src:\n","    dom_block = textwrap.dedent('''\n","    # ---------- Domain annotation (UniProt) and domain-colored viewer ----------\n","    @st.cache_data(show_spinner=False, ttl=86400)\n","    def fetch_uniprot_json(acc: str, timeout: int = 12):\n","        try:\n","            import json, urllib.request\n","            url = f\"https://rest.uniprot.org/uniprotkb/{acc}.json\"\n","            with urllib.request.urlopen(url, timeout=timeout) as r:\n","                return json.loads(r.read().decode(\"utf-8\",\"ignore\"))\n","        except Exception:\n","            return None\n","\n","    def domains_from_uniprot_json(j):\n","        segs=[]\n","        try:\n","            feats = (j or {}).get(\"features\") or []\n","            keep = {\"Domain\",\"Repeat\",\"Region\",\"Coiled coil\",\"Zinc finger\"}\n","            k=1\n","            for f in feats:\n","                t = f.get(\"type\")\n","                if t not in keep: continue\n","                loc = f.get(\"location\") or {}\n","                beg = ((loc.get(\"start\") or {}).get(\"value\"))\n","                end = ((loc.get(\"end\") or {}).get(\"value\"))\n","                if beg is None or end is None: continue\n","                try: beg = int(beg); end = int(end)\n","                except Exception: continue\n","                lab = f.get(\"description\") or t or f\"Domain {k}\"\n","                segs.append({\"start\": beg, \"end\": end, \"label\": lab, \"type\": t}); k+=1\n","        except Exception:\n","            pass\n","        return sorted(segs, key=lambda s:(s[\"start\"], s[\"end\"]))\n","\n","    def _domain_color(i):\n","        palette = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\"#8c564b\",\"#e377c2\",\"#7f7f7f\",\"#bcbd22\",\"#17becf\"]\n","        return palette[i % len(palette)]\n","\n","    def render_domains_py3d_html(txt: str, fmt: str, segs: list, style: str = \"Cartoon\", chain: str | None = None):\n","        viewer = py3Dmol.view(width=1000, height=650)\n","        viewer.addModel(txt, \"cif\" if fmt==\"cif\" else \"pdb\")\n","        viewer.setStyle({}, {\"cartoon\": {\"color\": \"#DDDDDD\"}})\n","        for i, s in enumerate(segs):\n","            sel = {\"resi\": list(range(int(s[\"start\"]), int(s[\"end\"])+1))}\n","            if chain: sel[\"chain\"] = chain\n","            col = _domain_color(i)\n","            if style == \"Cartoon\":\n","                viewer.setStyle(sel, {\"cartoon\": {\"color\": col}})\n","            elif style == \"Stick\":\n","                viewer.setStyle(sel, {\"stick\": {\"color\": col, \"radius\": 0.3}})\n","            elif style == \"Sphere\":\n","                viewer.setStyle(sel, {\"sphere\": {\"color\": col, \"radius\": 1.0}})\n","            elif style == \"Line\":\n","                viewer.setStyle(sel, {\"line\": {\"color\": col}})\n","            else:\n","                viewer.setStyle(sel, {\"cartoon\": {\"color\": col}})\n","        viewer.setBackgroundColor(\"white\"); viewer.zoomTo()\n","        return viewer._make_html()\n","\n","    def domain_legend_html(segs: list):\n","        items=[]\n","        for i, s in enumerate(segs):\n","            color = _domain_color(i)\n","            lab = f'{s.get(\"label\",\"Domain\")} ({s.get(\"start\",\"?\")}-{s.get(\"end\",\"?\")})'\n","            items.append(f'<div style=\"display:flex;align-items:center;margin:4px 0;\"><span style=\"display:inline-block;width:14px;height:14px;background:{color};border-radius:2px;margin-right:8px;\"></span>{lab}</div>')\n","        return '<div style=\"border:1px solid #e5e7eb;border-radius:10px;padding:10px;background:#fff;\">' + \"\".join(items) + \"</div>\"\n","\n","    def find_seq_name_by_model_path(path: str):\n","        try:\n","            p = str(path)\n","            for name, res in (st.session_state.get(\"results\") or {}).items():\n","                for m in (res.get(\"models\") or []):\n","                    if m.get(\"file\") == p: return name\n","        except Exception:\n","            pass\n","        return None\n","    ''').strip(\"\\n\")\n","    ins_pos = src.find(\"# ---------- AFDB helpers + Smart fetch ----------\")\n","    if ins_pos != -1:\n","        src = src[:ins_pos] + dom_block + \"\\n\\n\" + src[ins_pos:]\n","    else:\n","        src += \"\\n\\n\" + dom_block + \"\\n\"\n","    changed = True\n","\n","# 14) Ajouter le viewer Domaines (vertical) APR√àS le viewer pLDDT (page 3D)\n","if 'Domaines (UniProt)' not in src:\n","    pattern_v3d_call = re.compile(\n","        r'(display_plddt_panels\\(txt,\\s*fmt,\\s*label=path,\\s*sel_chain=sel_chain\\s*if\\s*mono\\s*else\\s*None,\\s*key_prefix=\"v3d\"\\)\\s*)'\n","    )\n","    domain_block = textwrap.dedent('''\n","    \\n# --- Viewer Domaines (bas) ---\n","    st.subheader(\"Domaines (UniProt)\")\n","    seq_name_guess = find_seq_name_by_model_path(path)\n","    try:\n","        acc_guess = resolve_accession_to_uniprot(seq_name_guess or \"\") if seq_name_guess else \"\"\n","    except Exception:\n","        acc_guess = \"\"\n","    up_acc_in = st.text_input(\"Accession UniProt pour domaines\", value=acc_guess or \"\", key=\"v3d_up_domains\")\n","    if up_acc_in:\n","        with st.spinner(\"R√©cup√©ration domaines (UniProt)‚Ä¶\"):\n","            j = fetch_uniprot_json(up_acc_in)\n","            segs = domains_from_uniprot_json(j) if j else []\n","        if segs:\n","            # Ne pas utiliser enhance_py3dmol_html ici pour ne pas √©craser les couleurs de domaines\n","            htmlD = render_domains_py3d_html(txt, fmt, segs, style=style, chain=(sel_chain if mono else None))\n","            htmlD = patch_py3dmol_html(htmlD)\n","            stampD = viewer_key(\"v3d-dom\", path=path, style=style, scheme=\"domains\", mono=mono, chain=sel_chain, first=first_model_only)\n","            htmlD = apply_viewer_stamp(htmlD, stampD)\n","            st.components.v1.html(htmlD, height=680)\n","            st.markdown(domain_legend_html(segs), unsafe_allow_html=True)\n","        else:\n","            st.info(\"Aucun domaine trouv√© pour cet ID UniProt.\")\n","    else:\n","        st.caption(\"Indiquez un ID UniProt (ex: P00533) pour colorer les domaines.\")\\n\n","    ''').strip(\"\\n\")\n","    src_new, n = pattern_v3d_call.subn(r'\\1' + domain_block, src, count=1)\n","    if n == 1:\n","        src = src_new; changed = True\n","\n","# 15) Sauvegarder\n","if changed:\n","    app_path.write_text(src, encoding=\"utf-8\")\n","    print(\"‚úÖ app.py patch√©.\")\n","else:\n","    print(\"‚ÑπÔ∏è Patch d√©j√† en place (aucune modification).\")\n","\n","# 16) Relancer Streamlit\n","Path(\".streamlit\").mkdir(exist_ok=True)\n","Path(\".streamlit/config.toml\").write_text(textwrap.dedent(\"\"\"\n","[server]\n","headless = true\n","address = \"0.0.0.0\"\n","port = 8501\n","enableCORS = false\n","enableXsrfProtection = false\n","[browser]\n","gatherUsageStats = false\n","\"\"\").strip()+\"\\n\", encoding=\"utf-8\")\n","\n","subprocess.Popen(\n","    [sys.executable, \"-m\", \"streamlit\", \"run\", \"app.py\", \"--server.port\",\"8501\",\"--server.address\",\"0.0.0.0\"],\n","    stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT\n",")\n","time.sleep(6)\n","\n","# 17) public_url.txt (liens absolus)\n","try:\n","    from google.colab import output\n","    public_url = output.eval_js(\"google.colab.kernel.proxyPort(8501)\")\n","    Path(\"public_url.txt\").write_text(public_url.strip(), encoding=\"utf-8\")\n","    print(f\"üåê URL (proxy Colab): {public_url}\")\n","except Exception:\n","    Path(\"public_url.txt\").write_text(\"http://localhost:8501\", encoding=\"utf-8\")\n","    print(\"üåê URL locale: http://localhost:8501\")\n","\n","print(\"üéâ Termin√© ‚Äî NameError r√©solu, pLDDT au-dessus ‚Ä¢ Domaines au-dessous, correctifs appliqu√©s.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"fY74rty1uf6x","executionInfo":{"status":"ok","timestamp":1766569982183,"user_tz":-60,"elapsed":16334,"user":{"displayName":"","userId":""}},"outputId":"da5fb49c-87b1-4900-b7fe-5db6064edce1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚Üí pip streamlit==1.28.0\n","‚Üí pip plotly==5.17.0\n","‚Üí pip py3Dmol==2.1.0\n","‚Üí pip numpy==1.26.4\n","‚úÖ app.py patch√©.\n","üåê URL (proxy Colab): https://8501-gpu-t4-s-11m6er7faugg1-c.asia-southeast1-1.prod.colab.dev\n","üéâ Termin√© ‚Äî NameError r√©solu, pLDDT au-dessus ‚Ä¢ Domaines au-dessous, correctifs appliqu√©s.\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/pro.ipynb","timestamp":1766571390767}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}